{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Task3 of “CNN_Lab-01-MNIST-MLP-vs-CNN-Bakeoff.ipynb” by Pepper",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PepperJao/Modeling/blob/master/Task3_of_%E2%80%9CCNN_Lab_01_MNIST_MLP_vs_CNN_Bakeoff_ipynb%E2%80%9D_by_Pepper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FoamsT_fGzm",
        "colab_type": "text"
      },
      "source": [
        "# Convolutional Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYv-gV0VfGzo",
        "colab_type": "text"
      },
      "source": [
        "In this notebook we're going to explore handwritten digit recognition task using MNIST database and CNNs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paLHNhLNfGzp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras import backend as K\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "\n",
        "from IPython.display import SVG\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjbNIorbfGzv",
        "colab_type": "text"
      },
      "source": [
        "Set style"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zroizrkMfGzw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.set(style=\"whitegrid\", font_scale=1.3)\n",
        "matplotlib.rcParams[\"figure.figsize\"] = (10, 8)\n",
        "matplotlib.rcParams[\"legend.framealpha\"] = 1\n",
        "matplotlib.rcParams[\"legend.frameon\"] = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0fmqnW5fGzz",
        "colab_type": "text"
      },
      "source": [
        "Just for the sake of reproducibility"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYmsiOAUfGz0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(41)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSgtA7HefGz3",
        "colab_type": "text"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbOSqLNwfGz4",
        "colab_type": "text"
      },
      "source": [
        "In this tutorial we're going to use MNIST dataset with handwritten digits."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1TerpNhfGz4",
        "colab_type": "text"
      },
      "source": [
        "## MNIST overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGxOQElFfGz5",
        "colab_type": "text"
      },
      "source": [
        "Let's download MNIST dataset. There is a special function in Keras for that purpose (because MNIST is extremely popular)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjKK2nLgfGz6",
        "colab_type": "code",
        "outputId": "97989367-1373-4798-dd14-f3249d9d3984",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "print(len(X_train), 'train samples')\n",
        "print(len(X_test), 'test samples')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGMuPtA8fGz9",
        "colab_type": "code",
        "outputId": "d99fbe25-0b06-4f09-9499-555b96b1bd2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "source": [
        "plt.figure(figsize=(12, 5))\n",
        "for num, i in enumerate(np.random.choice(len(X_train), 10)):\n",
        "    plt.subplot(2, 5, num + 1)\n",
        "    plt.imshow(X_train[i], cmap=\"Greys_r\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(str(y_train[i]))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAE/CAYAAACq327HAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAwaI4BAAAA4/8BGGZ+ghUsz64AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 864x360 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9V1Cu5gLfG0A",
        "colab_type": "text"
      },
      "source": [
        "Let's see objects are distributed among classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cf1l2szgfG0B",
        "colab_type": "code",
        "outputId": "17a52d2c-198a-4ca2-f69c-ddeccfd71f3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        }
      },
      "source": [
        "x_bars, y_bars = np.unique(y_train, return_counts=True)\n",
        "plt.bar(x_bars, y_bars)\n",
        "plt.xlim([-1, 10])\n",
        "plt.xticks(np.arange(0, 10))\n",
        "plt.xlabel(\"Digit\", fontsize=14)\n",
        "plt.ylabel(\"Number of pics\", fontsize=14)\n",
        "plt.show()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoIAAAHwCAYAAAAy8g5CAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nADAogiAAAIBBEQQBAAAM6v8Bq16w88UqsbMAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 720x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ja1K7-6NfG0E",
        "colab_type": "text"
      },
      "source": [
        "As one can see, the task is pretty balanced"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8d3SgXwfG0F",
        "colab_type": "text"
      },
      "source": [
        "## Data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nELBJWLWfG0G",
        "colab_type": "text"
      },
      "source": [
        "First of all, let's predefine image parameters:\n",
        "* **img_rows, img_cols** $-$ 2D dimension of a pictures; for MNIST it is $28 \\times 28$\n",
        "* **nb_classes** $-$ number of classes (digits in our case)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weRpIIdgfG0H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_rows, img_cols = 28, 28\n",
        "nb_classes = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4Bo7tGrfG0K",
        "colab_type": "text"
      },
      "source": [
        "Theano and Tensorflow both are tensor-based libraries. It means that all objects inside it, all inputs and outputs are **tensors**. One can treat tensor as a simple multidimensional array."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJa_9xZifG0L",
        "colab_type": "text"
      },
      "source": [
        "The thing that is different in Theano and Tensorflow is order of these dimensions inside tensor.\n",
        "\n",
        "With Theano yo're going to have 4-dimensional tensor with the following dimensions: **(Objects, Channels, Image rows,Image columns)**. Assume that $\\text{X_train}$ is our tensor. Then $\\text{X_train}[0]$ gives you one trainig object - it is an image with few channels in general case. $\\text{X_train}[0][0]$ gives you the first channel of the first object. And so on. The logic of tensors should be clear now.\n",
        "\n",
        "In Tensorflow the order is the following: **(Objects, Image rows,Image columns, Channels)**\n",
        "\n",
        "Thus we need to check what dimension order do we have and reshape our tensor in accordance with it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1Zw_ciIfG0L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_rows, img_cols = 28, 28\n",
        "nb_classes = 10\n",
        "if K.image_dim_ordering() == 'th':\n",
        "    X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n",
        "    X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
        "    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7q8m-bHfG0O",
        "colab_type": "text"
      },
      "source": [
        "Here we have grayscale image and thus the number of the channels is $1$. Here I used Tensorflow library with the corresponding order of dimensions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WzuMj7DfG0P",
        "colab_type": "code",
        "outputId": "126fe1a4-5f1b-41b1-c201-39bcac89730f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('X_train shape:', X_train.shape)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train shape: (60000, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMjjRiUvfG0V",
        "colab_type": "text"
      },
      "source": [
        "Tensorflow prefers to work with $\\text{float32}$ data type. So the next step is to cast data. Also let's have our data in $[0; 1]$ interval $-$ it's common choice for grayscale images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssrT7VyLfG0W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itix4_vWfG0Y",
        "colab_type": "text"
      },
      "source": [
        "Last step is to convert labels into [One-Hot Encoding](https://en.wikipedia.org/wiki/One-hot) because we're going to learn them through the softmax layer in CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MamhvkNrfG0Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = to_categorical(y_train, nb_classes)\n",
        "y_test = to_categorical(y_test, nb_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "liUjQn3CfG0c",
        "colab_type": "text"
      },
      "source": [
        "# Dense baseline model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fY5aHvxfG0d",
        "colab_type": "text"
      },
      "source": [
        "First of all, let's build MLP model and see how it performs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_R0tswXfG0e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_dense = Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJ0WxzNbfG0i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "\n",
        "model_dense.add(Dense(128, input_shape=(img_rows * img_cols,), activation=\"relu\"))\n",
        "model_dense.add(Dropout(0.5))\n",
        "model_dense.add(Dense(128, activation=\"relu\"))\n",
        "model_dense.add(Dropout(0.5))\n",
        "model_dense.add(Dense(128, activation=\"relu\"))\n",
        "model_dense.add(Dropout(0.5))\n",
        "model_dense.add(Dense(nb_classes, activation=\"softmax\"))\n",
        "'''\n",
        "model_dense.add(Dense(256, input_shape=(img_rows * img_cols,), activation=\"relu\"))\n",
        "model_dense.add(Dropout(0.5))\n",
        "model_dense.add(Dense(nb_classes, activation=\"softmax\"))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-AbmxiafG0o",
        "colab_type": "text"
      },
      "source": [
        "Our model the the following architercture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6sC2dV_fG0p",
        "colab_type": "code",
        "outputId": "a62ba2fa-5599-4e79-eef1-c3368de28311",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        }
      },
      "source": [
        "model_dense.summary()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_7 (Dense)              (None, 256)               200960    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 203,530\n",
            "Trainable params: 203,530\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8vBTTq5gCzf",
        "colab_type": "code",
        "outputId": "d331f8e7-d805-45b5-ea3d-0806e2a45ffb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        }
      },
      "source": [
        "SVG(model_to_dot(model_dense, show_shapes=True).create(prog='dot', format='svg'))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"294pt\" viewBox=\"0.00 0.00 287.00 294.00\" width=\"287pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 290)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-290 283,-290 283,4 -4,4\" stroke=\"transparent\"/>\n<!-- 140112565289368 -->\n<g class=\"node\" id=\"node1\">\n<title>140112565289368</title>\n<polygon fill=\"none\" points=\"13.5,-166.5 13.5,-212.5 265.5,-212.5 265.5,-166.5 13.5,-166.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"67\" y=\"-185.8\">dense_7: Dense</text>\n<polyline fill=\"none\" points=\"120.5,-166.5 120.5,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"149.5\" y=\"-197.3\">input:</text>\n<polyline fill=\"none\" points=\"120.5,-189.5 178.5,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"149.5\" y=\"-174.3\">output:</text>\n<polyline fill=\"none\" points=\"178.5,-166.5 178.5,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"222\" y=\"-197.3\">(None, 784)</text>\n<polyline fill=\"none\" points=\"178.5,-189.5 265.5,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"222\" y=\"-174.3\">(None, 256)</text>\n</g>\n<!-- 140112565290768 -->\n<g class=\"node\" id=\"node2\">\n<title>140112565290768</title>\n<polygon fill=\"none\" points=\"0,-83.5 0,-129.5 279,-129.5 279,-83.5 0,-83.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"67\" y=\"-102.8\">dropout_2: Dropout</text>\n<polyline fill=\"none\" points=\"134,-83.5 134,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"163\" y=\"-114.3\">input:</text>\n<polyline fill=\"none\" points=\"134,-106.5 192,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"163\" y=\"-91.3\">output:</text>\n<polyline fill=\"none\" points=\"192,-83.5 192,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"235.5\" y=\"-114.3\">(None, 256)</text>\n<polyline fill=\"none\" points=\"192,-106.5 279,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"235.5\" y=\"-91.3\">(None, 256)</text>\n</g>\n<!-- 140112565289368&#45;&gt;140112565290768 -->\n<g class=\"edge\" id=\"edge2\">\n<title>140112565289368-&gt;140112565290768</title>\n<path d=\"M139.5,-166.3799C139.5,-158.1745 139.5,-148.7679 139.5,-139.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"143.0001,-139.784 139.5,-129.784 136.0001,-139.784 143.0001,-139.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140112565291216 -->\n<g class=\"node\" id=\"node3\">\n<title>140112565291216</title>\n<polygon fill=\"none\" points=\"13.5,-.5 13.5,-46.5 265.5,-46.5 265.5,-.5 13.5,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"67\" y=\"-19.8\">dense_8: Dense</text>\n<polyline fill=\"none\" points=\"120.5,-.5 120.5,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"149.5\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"120.5,-23.5 178.5,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"149.5\" y=\"-8.3\">output:</text>\n<polyline fill=\"none\" points=\"178.5,-.5 178.5,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"222\" y=\"-31.3\">(None, 256)</text>\n<polyline fill=\"none\" points=\"178.5,-23.5 265.5,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"222\" y=\"-8.3\">(None, 10)</text>\n</g>\n<!-- 140112565290768&#45;&gt;140112565291216 -->\n<g class=\"edge\" id=\"edge3\">\n<title>140112565290768-&gt;140112565291216</title>\n<path d=\"M139.5,-83.3799C139.5,-75.1745 139.5,-65.7679 139.5,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"143.0001,-56.784 139.5,-46.784 136.0001,-56.784 143.0001,-56.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140112565291048 -->\n<g class=\"node\" id=\"node4\">\n<title>140112565291048</title>\n<polygon fill=\"none\" points=\"75.5,-249.5 75.5,-285.5 203.5,-285.5 203.5,-249.5 75.5,-249.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"139.5\" y=\"-263.8\">140112565291048</text>\n</g>\n<!-- 140112565291048&#45;&gt;140112565289368 -->\n<g class=\"edge\" id=\"edge1\">\n<title>140112565291048-&gt;140112565289368</title>\n<path d=\"M139.5,-249.4092C139.5,-241.4308 139.5,-231.795 139.5,-222.606\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"143.0001,-222.5333 139.5,-212.5333 136.0001,-222.5334 143.0001,-222.5333\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_U-Dr-O9fG0t",
        "colab_type": "text"
      },
      "source": [
        "Compile model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3U4WVFJfG0t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_dense.compile(loss='categorical_crossentropy',\n",
        "                    optimizer='adam',\n",
        "                    metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kh477LQtfG0w",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuG_25o3fG0w",
        "colab_type": "code",
        "outputId": "79a614f5-73c9-4a05-9a85-2a29dadaab79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        }
      },
      "source": [
        "hist = model_dense.fit(X_train.reshape((len(X_train), img_cols * img_rows)), y_train, \n",
        "                       validation_data = (X_test.reshape((len(X_test), img_cols * img_rows)), y_test), \n",
        "                       epochs=20, batch_size=128)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "60000/60000 [==============================] - 4s 72us/step - loss: 0.4052 - acc: 0.8802 - val_loss: 0.1780 - val_acc: 0.9478\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.1971 - acc: 0.9422 - val_loss: 0.1263 - val_acc: 0.9622\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 4s 64us/step - loss: 0.1522 - acc: 0.9563 - val_loss: 0.1027 - val_acc: 0.9682\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.1275 - acc: 0.9619 - val_loss: 0.0914 - val_acc: 0.9733\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.1139 - acc: 0.9660 - val_loss: 0.0825 - val_acc: 0.9740\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.1005 - acc: 0.9697 - val_loss: 0.0787 - val_acc: 0.9768\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.0914 - acc: 0.9719 - val_loss: 0.0726 - val_acc: 0.9786\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.0837 - acc: 0.9742 - val_loss: 0.0707 - val_acc: 0.9784\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.0800 - acc: 0.9747 - val_loss: 0.0677 - val_acc: 0.9786\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.0748 - acc: 0.9764 - val_loss: 0.0685 - val_acc: 0.9785\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.0669 - acc: 0.9786 - val_loss: 0.0680 - val_acc: 0.9799\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.0660 - acc: 0.9789 - val_loss: 0.0628 - val_acc: 0.9808\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.0616 - acc: 0.9800 - val_loss: 0.0615 - val_acc: 0.9816\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.0586 - acc: 0.9810 - val_loss: 0.0622 - val_acc: 0.9798\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.0576 - acc: 0.9808 - val_loss: 0.0625 - val_acc: 0.9806\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.0527 - acc: 0.9834 - val_loss: 0.0618 - val_acc: 0.9804\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.0531 - acc: 0.9830 - val_loss: 0.0642 - val_acc: 0.9802\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.0475 - acc: 0.9844 - val_loss: 0.0620 - val_acc: 0.9817\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 4s 68us/step - loss: 0.0463 - acc: 0.9845 - val_loss: 0.0601 - val_acc: 0.9820\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.0460 - acc: 0.9844 - val_loss: 0.0637 - val_acc: 0.9827\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETyGKbG2fG00",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ah8eM5OjfG01",
        "colab_type": "text"
      },
      "source": [
        "Learning process visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZYknxcjfG02",
        "colab_type": "code",
        "outputId": "8df825d2-c2f9-45fe-e45e-5a21f5b5e4ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 686
        }
      },
      "source": [
        "plt.figure(figsize=(20, 8))\n",
        "plt.suptitle(\"Dense model training\", fontsize=18)\n",
        "plt.subplot(121)\n",
        "plt.plot(hist.history[\"loss\"], label=\"Train\")\n",
        "plt.plot(hist.history[\"val_loss\"], label=\"Test\")\n",
        "plt.grid(\"on\")\n",
        "plt.xlabel(\"Epoch\", fontsize=14)\n",
        "plt.ylabel(\"Crossentropy\", fontsize=14)\n",
        "plt.legend(loc=\"upper right\")\n",
        "plt.subplot(122)\n",
        "plt.plot(hist.history[\"acc\"], label=\"Train\")\n",
        "plt.grid(\"on\")\n",
        "plt.plot(hist.history[\"val_acc\"], label=\"Test\")\n",
        "plt.xlabel(\"Epoch\", fontsize=14)\n",
        "plt.ylabel(\"Accuracy\", fontsize=14)\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.ylim([0.88, 1.0]);"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/matplotlib/cbook/__init__.py:424: MatplotlibDeprecationWarning: \n",
            "Passing one of 'on', 'true', 'off', 'false' as a boolean is deprecated; use an actual boolean (True/False) instead.\n",
            "  warn_deprecated(\"2.2\", \"Passing one of 'on', 'true', 'off', 'false' as a \"\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/cbook/__init__.py:424: MatplotlibDeprecationWarning: \n",
            "Passing one of 'on', 'true', 'off', 'false' as a boolean is deprecated; use an actual boolean (True/False) instead.\n",
            "  warn_deprecated(\"2.2\", \"Passing one of 'on', 'true', 'off', 'false' as a \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABKsAAAIkCAYAAADRSKi/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 1440x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAJQ9octfG05",
        "colab_type": "text"
      },
      "source": [
        "Table to store the results of the experiments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LduFGvHKfG06",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score_train = model_dense.evaluate(X_train.reshape((len(X_train), img_cols * img_rows)), y_train, verbose=0)\n",
        "score_test = model_dense.evaluate(X_test.reshape((len(X_test), img_cols * img_rows)), y_test, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3oLnGc_fG08",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results = pd.DataFrame(columns=[\"Architecture\", \"Epoch time\", \"Accuracy Train\", \"Accuracy Test\", \"Loss Train\", \"Loss Test\"])\n",
        "results.loc[len(results)] = np.array([\"784-128-128-128-10\", \"2secs\", score_train[1], score_test[1], score_train[0], score_test[0]])\n",
        "results.index = [\"MLP\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_F3wuQEgfG1D",
        "colab_type": "code",
        "outputId": "bf24aab9-c027-4a9a-f5a1-6ebf63fa9c19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        }
      },
      "source": [
        "results"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Architecture</th>\n",
              "      <th>Epoch time</th>\n",
              "      <th>Accuracy Train</th>\n",
              "      <th>Accuracy Test</th>\n",
              "      <th>Loss Train</th>\n",
              "      <th>Loss Test</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>MLP</th>\n",
              "      <td>784-128-128-128-10</td>\n",
              "      <td>2secs</td>\n",
              "      <td>0.9962666666666666</td>\n",
              "      <td>0.9827</td>\n",
              "      <td>0.013983017520932482</td>\n",
              "      <td>0.06370132064592908</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Architecture Epoch time      Accuracy Train Accuracy Test  \\\n",
              "MLP  784-128-128-128-10      2secs  0.9962666666666666        0.9827   \n",
              "\n",
              "               Loss Train            Loss Test  \n",
              "MLP  0.013983017520932482  0.06370132064592908  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owbSbSxjG19w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "outputId": "be2de5c9-a01a-427f-de79-37c39f2fd1aa"
      },
      "source": [
        "print(y_train[0:19])#0 4 1 2 3"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuu-FKOUNdmi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "9ca887c2-6c0e-4724-e8a6-680848d175c0"
      },
      "source": [
        "\n",
        "\n",
        "#y_train_selected=np.append(y_train_selected,y_train[metrix:metrix+1],axis=0)\n",
        "even=y_train[1:2]\n",
        "odd=y_train[3:4]\n",
        "for i in [ 5,2,13,17]:\n",
        "  even=np.append(even,y_train[i:i+1],axis=0)\n",
        "for i in [ 7,0,15,4]:\n",
        "  odd=np.append(odd,y_train[i:i+1],axis=0)\n",
        "\n",
        "  \n",
        "\n",
        "          \n",
        "if y_train[1:2] in even:\n",
        "  print(even)\n",
        "print(odd)\n"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]]\n",
            "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sn_BoG1DXcO",
        "colab_type": "code",
        "outputId": "e6a1d004-c9f9-438c-f252-2a8afb60fa7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "#tuple & list operation\n",
        "tup=(1,2,3,4,5)\n",
        "lst=list(tup)\n",
        "print(len(lst))\n",
        "\n",
        "i=0\n",
        "while i < len(lst):\n",
        "    if (lst[i]%2)==0:\n",
        "        lst[i]=0\n",
        "    else:\n",
        "        lst[i]=1\n",
        "    i+=1\n",
        "print(lst)\n",
        "\n",
        "tup=tuple(lst)\n",
        "print(tup)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n",
            "[1, 0, 1, 0, 1]\n",
            "(1, 0, 1, 0, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Y-uv7zu85TrZ"
      },
      "source": [
        "##Homework by Pepper\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vereTAZGY8dN",
        "colab_type": "text"
      },
      "source": [
        "### Task 3.1 : choose a better MLP architecture\n",
        "\n",
        "\n",
        "\n",
        "Using all the training data, search for a good CNN architecture to model the MNIST problem. Above we explored 784-128-128-128-10.\n",
        " \n",
        "\n",
        "It is up to you what the model will be. Here are some things you need to decide:\n",
        "1. how many DENSE layers?\n",
        "```python\n",
        "'3 dense layers'\n",
        "'1 hidden layers'\n",
        "```\n",
        "* how manu neurons per layer\n",
        "```python\n",
        "'256 per layer'\n",
        "```\n",
        "* report the accuracy on the test data set\n",
        "```python\n",
        "'784-256-10\t\taccuracy_train:0.99995\taccuracy_test:0.982'\n",
        "```\n",
        "**Please paste your response here using the following format:** \n",
        "* Best archtecture is:  \n",
        "```python\n",
        "'784-256-10\t\t\n",
        "```\n",
        "* Test accuracy: \n",
        "```python\n",
        "'accuracy_train:0.99995\taccuracy_test:0.982'\n",
        "```\n",
        "* Training time per epoch in seconds is : \n",
        "```python\n",
        "'1secs'\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "cellView": "code",
        "outputId": "8edaaa5b-c0bc-4922-c991-24f702f8d598",
        "id": "bdQqzhV35Tra",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "\n",
        "#written by Pepper before 5pm Tuesday\n",
        "\n",
        "results = pd.DataFrame(columns=[\"Architecture\", \"Epoch time\", \"Accuracy Train\", \"Accuracy Test\", \"Loss Train\", \"Loss Test\"])\n",
        "\n",
        "\n",
        "for dense_layer in [4,3,2,1]:\n",
        "  for neuron in [256,128,64,12]:\n",
        "    architecture = '784-'+str(neuron)  \n",
        "    \n",
        "    model_dense = Sequential()  \n",
        "    model_dense.add(Dense(neuron, input_shape=(img_rows * img_cols,), activation=\"relu\"))\n",
        "    \n",
        "    time = 1\n",
        "    while time < dense_layer:#pair other nodes using while loop\n",
        "      architecture+='-'+str(neuron)   \n",
        "      model_dense.add(Dense(neuron, activation=\"relu\"))\n",
        "      time+=1\n",
        "             \n",
        "'''\n",
        "#2nd version\n",
        "#def list_all_architecture():\n",
        "neurons=[256,128,64,12]\n",
        "for dense_layer in range(1,4):#list all achitecture using 2 for loops\n",
        "  for n in range(1,4):\n",
        "    architecture = '784-'+str(neurons[n]) #architecture name     \n",
        "    \n",
        "    model_dense = Sequential()  \n",
        "    model_dense.add(Dense(neurons[n], input_shape=(img_rows * img_cols,), activation=\"relu\"))\n",
        "    \n",
        "    \n",
        "    \n",
        "    while n < dense_layer:#pair other nodes using while loop\n",
        "      architecture+='-'+str(neurons[n+1])  #architecture name   \n",
        "      \n",
        "      model_dense.add(Dense(neurons[n+1], activation=\"relu\"))\n",
        "      time+=1\n",
        " '''  \n",
        "      \n",
        "      \n",
        "    model_dense.add(Dense(nb_classes, activation=\"softmax\"))\n",
        "    architecture+=\"-10\"\n",
        "      \n",
        "    #compile before training & testing  \n",
        "    model_dense.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    #training & testing (thought this was plotting and deleted, and got 0.01% of accuracy)\n",
        "    hist = model_dense.fit(X_train.reshape((len(X_train), img_cols * img_rows)), y_train, \n",
        "          validation_data = (X_test.reshape((len(X_test), img_cols * img_rows)), y_test), \n",
        "          epochs=20, batch_size=128)\n",
        "\n",
        "    \n",
        "    \n",
        "    score_train = model_dense.evaluate(X_train.reshape((len(X_train), img_cols * img_rows)), y_train, verbose=0)\n",
        "    score_test = model_dense.evaluate(X_test.reshape((len(X_test), img_cols * img_rows)), y_test, verbose=0)\n",
        "\n",
        "\n",
        "      \n",
        "    results.loc[len(results)] = np.array([architecture, \"1secs\", score_train[1], score_test[1], score_train[0], score_test[0]])\n",
        "    #results.index = [\"MLP\"]\n",
        "\n",
        "results\n",
        "      \n",
        "#list_all_architecture()\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n#written by Pepper before 5pm Tuesday\\n\\nresults = pd.DataFrame(columns=[\"Architecture\", \"Epoch time\", \"Accuracy Train\", \"Accuracy Test\", \"Loss Train\", \"Loss Test\"])\\n\\n\\nfor dense_layer in [4,3,2,1]:\\n  for neuron in [256,128,64,12]:\\n    architecture = \\'784-\\'+str(neuron)  \\n    \\n    model_dense = Sequential()  \\n    model_dense.add(Dense(neuron, input_shape=(img_rows * img_cols,), activation=\"relu\"))\\n    \\n    time = 1\\n    while time < dense_layer:#pair other nodes using while loop\\n      architecture+=\\'-\\'+str(neuron)   \\n      model_dense.add(Dense(neuron, activation=\"relu\"))\\n      time+=1\\n             \\n\\'\\'\\n#def list_all_architecture():\\nneurons=[256,128,64,12]\\nfor dense_layer in range(1,4):#list all achitecture using 2 for loops\\n  for n in range(1,4):\\n    architecture = \\'784-\\'+str(neurons[n]) #architecture name     \\n    \\n    model_dense = Sequential()  \\n    model_dense.add(Dense(neurons[n], input_shape=(img_rows * img_cols,), activation=\"relu\"))\\n    \\n    \\n    \\n    while n < dense_layer:#pair other nodes using while loop\\n      architecture+=\\'-\\'+str(neurons[n+1])  #architecture name   \\n      \\n      model_dense.add(Dense(neurons[n+1], activation=\"relu\"))\\n      time+=1\\n \\'\\'   \\n      \\n      \\n    model_dense.add(Dense(nb_classes, activation=\"softmax\"))\\n    architecture+=\"-10\"\\n      \\n    #compile before training & testing  \\n    model_dense.compile(loss=\\'categorical_crossentropy\\',\\n                  optimizer=\\'adam\\',\\n                  metrics=[\\'accuracy\\'])\\n    \\n    #training & testing (thought this was plotting and deleted, and got 0.01% of accuracy)\\n    hist = model_dense.fit(X_train.reshape((len(X_train), img_cols * img_rows)), y_train, \\n          validation_data = (X_test.reshape((len(X_test), img_cols * img_rows)), y_test), \\n          epochs=20, batch_size=128)\\n\\n    \\n    \\n    score_train = model_dense.evaluate(X_train.reshape((len(X_train), img_cols * img_rows)), y_train, verbose=0)\\n    score_test = model_dense.evaluate(X_test.reshape((len(X_test), img_cols * img_rows)), y_test, verbose=0)\\n\\n\\n      \\n    results.loc[len(results)] = np.array([architecture, \"1secs\", score_train[1], score_test[1], score_train[0], score_test[0]])\\n    #results.index = [\"MLP\"]\\n\\nresults\\n      \\n#list_all_architecture()'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDvLetT_g6Bd",
        "colab_type": "text"
      },
      "source": [
        "###Task 3.2 : with 500 training examples\n",
        "\n",
        "Use only 500 examples per class (recall we  have only 10 classes) and find the best architecture. (HINT you can do  stratified sampling OR just random selxtion of 5,000 examples)\n",
        "\n",
        "**Please paste your response here:** \n",
        "* Best archtecture is:  \n",
        "784-256-256-256-256-10\t\n",
        "* Test accuracy: \n",
        "\n",
        " 0.8731\n",
        "* Training time per epoch in seconds is : \n",
        "\n",
        " 1secs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9_OOZGyy_mD",
        "colab_type": "code",
        "outputId": "54a134b4-c20e-42ac-ad7f-5a5ca018b472",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 11974
        }
      },
      "source": [
        "\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "'''\n",
        "\n",
        "\n",
        "#X_train & y_train are matrices\n",
        "list_random=np.random.random(500)*59999\n",
        "#list_random=np.random.randint(2,len(X_train)-1)\n",
        "for matrix in list_random:\n",
        "  X_train_selected=X_train[0:1]\n",
        "  y_train_selected=y_train[0:1]\n",
        "  matrix= int(round(matrix))\n",
        "  #print(len(list_random))\n",
        "  #print(matrix)\n",
        "  #print(X_train[matrix:matrix+1])\n",
        "  X_train_selected=np.append(X_train_selected,X_train[matrix:matrix+1],axis=0)\n",
        "  y_train_selected=np.append(y_train_selected,y_train[matrix:matrix+1],axis=0)\n",
        "\n",
        "print(len(X_train_selected))\n",
        "'''\n",
        "\n",
        "#randomly select\n",
        "\n",
        "X_train_selected=X_train[0:1]\n",
        "y_train_selected=y_train[0:1]\n",
        "X_test_selected=X_test[0:1]\n",
        "y_test_selected=y_test[0:1]\n",
        "#list_random=np.random.random(5)*(len(X_train)-1)\n",
        "i=0\n",
        "while(i<500):\n",
        "\n",
        "    metrix=np.random.randint(2,59999)\n",
        "    X_train_selected=np.append(X_train_selected,X_train[metrix:metrix+1],axis=0)\n",
        "    y_train_selected=np.append(y_train_selected,y_train[metrix:metrix+1],axis=0)\n",
        "    i=i+1\n",
        "i=0\n",
        "while(i<100):\n",
        "    i=i+1\n",
        "    metrix2=np.random.randint(2,10000)\n",
        "    X_test_selected=np.append(X_test_selected,X_test[metrix:metrix+1],axis=0)\n",
        "    y_test_selected=np.append(y_test_selected,y_test[metrix:metrix+1],axis=0)\n",
        "    \n",
        "#print(len(X_train_selected))\n",
        "\n",
        "#train\n",
        "results = pd.DataFrame(columns=[\"Architecture\", \"Epoch time\", \"Accuracy Train\", \"Accuracy Test\", \"Loss Train\", \"Loss Test\"])\n",
        "\n",
        "\n",
        "for dense_layer in [4,3,2,1]:\n",
        "  for neuron in [256,128,64,12]:\n",
        "    architecture = '784-'+str(neuron)  \n",
        "    \n",
        "    model_dense = Sequential()  \n",
        "    model_dense.add(Dense(neuron, input_shape=(img_rows * img_cols,), activation=\"relu\"))\n",
        "    \n",
        "    time = 1\n",
        "    while time < dense_layer:#pair other nodes using while loop\n",
        "      architecture+='-'+str(neuron)   \n",
        "      model_dense.add(Dense(neuron, activation=\"relu\"))\n",
        "      time+=1\n",
        "             \n",
        "\n",
        "      \n",
        "      \n",
        "    model_dense.add(Dense(nb_classes, activation=\"softmax\"))\n",
        "    architecture+=\"-10\"\n",
        "      \n",
        "    #compile before training & testing  \n",
        "    model_dense.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    #training & testing (thought this was plotting and deleted, and got 0.01% of accuracy)\n",
        "    hist = model_dense.fit(X_train_selected.reshape((len(X_train_selected), img_cols * img_rows)), y_train_selected, \n",
        "          validation_data = (X_test_selected.reshape((len(X_test_selected), img_cols * img_rows)), y_test_selected), \n",
        "          epochs=20, batch_size=128)\n",
        "\n",
        "    \n",
        "    \n",
        "    score_train = model_dense.evaluate(X_train_selected.reshape((len(X_train_selected), img_cols * img_rows)), y_train_selected, verbose=0)\n",
        "    score_test = model_dense.evaluate(X_test_selected.reshape((len(X_test_selected), img_cols * img_rows)), y_test_selected, verbose=0)\n",
        "\n",
        "\n",
        "      \n",
        "    results.loc[len(results)] = np.array([architecture, \"1secs\", score_train[1], score_test[1], score_train[0], score_test[0]])\n",
        "    #results.index = [\"MLP\"]\n",
        "\n",
        "results\n",
        "      "
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 501 samples, validate on 1 samples\n",
            "Epoch 1/20\n",
            "501/501 [==============================] - 2s 5ms/step - loss: 2.2094 - acc: 0.2455 - val_loss: 2.0540 - val_acc: 1.0000\n",
            "Epoch 2/20\n",
            "501/501 [==============================] - 0s 139us/step - loss: 1.7456 - acc: 0.6188 - val_loss: 1.2299 - val_acc: 1.0000\n",
            "Epoch 3/20\n",
            "501/501 [==============================] - 0s 132us/step - loss: 1.0779 - acc: 0.7585 - val_loss: 0.3095 - val_acc: 1.0000\n",
            "Epoch 4/20\n",
            "501/501 [==============================] - 0s 131us/step - loss: 0.5843 - acc: 0.8683 - val_loss: 0.0283 - val_acc: 1.0000\n",
            "Epoch 5/20\n",
            "501/501 [==============================] - 0s 132us/step - loss: 0.3767 - acc: 0.8982 - val_loss: 0.0052 - val_acc: 1.0000\n",
            "Epoch 6/20\n",
            "501/501 [==============================] - 0s 134us/step - loss: 0.2420 - acc: 0.9281 - val_loss: 9.1976e-04 - val_acc: 1.0000\n",
            "Epoch 7/20\n",
            "501/501 [==============================] - 0s 131us/step - loss: 0.1596 - acc: 0.9561 - val_loss: 1.3251e-04 - val_acc: 1.0000\n",
            "Epoch 8/20\n",
            "501/501 [==============================] - 0s 133us/step - loss: 0.1125 - acc: 0.9621 - val_loss: 8.2056e-04 - val_acc: 1.0000\n",
            "Epoch 9/20\n",
            "501/501 [==============================] - 0s 138us/step - loss: 0.0770 - acc: 0.9820 - val_loss: 4.0115e-05 - val_acc: 1.0000\n",
            "Epoch 10/20\n",
            "501/501 [==============================] - 0s 129us/step - loss: 0.0420 - acc: 0.9940 - val_loss: 1.2279e-04 - val_acc: 1.0000\n",
            "Epoch 11/20\n",
            "501/501 [==============================] - 0s 140us/step - loss: 0.0292 - acc: 0.9940 - val_loss: 7.0932e-05 - val_acc: 1.0000\n",
            "Epoch 12/20\n",
            "501/501 [==============================] - 0s 134us/step - loss: 0.0203 - acc: 1.0000 - val_loss: 1.6570e-05 - val_acc: 1.0000\n",
            "Epoch 13/20\n",
            "501/501 [==============================] - 0s 128us/step - loss: 0.0129 - acc: 1.0000 - val_loss: 2.4081e-05 - val_acc: 1.0000\n",
            "Epoch 14/20\n",
            "501/501 [==============================] - 0s 136us/step - loss: 0.0094 - acc: 1.0000 - val_loss: 2.0147e-05 - val_acc: 1.0000\n",
            "Epoch 15/20\n",
            "501/501 [==============================] - 0s 141us/step - loss: 0.0053 - acc: 1.0000 - val_loss: 3.9339e-06 - val_acc: 1.0000\n",
            "Epoch 16/20\n",
            "501/501 [==============================] - 0s 128us/step - loss: 0.0051 - acc: 1.0000 - val_loss: 2.6226e-06 - val_acc: 1.0000\n",
            "Epoch 17/20\n",
            "501/501 [==============================] - 0s 134us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 3.8147e-06 - val_acc: 1.0000\n",
            "Epoch 18/20\n",
            "501/501 [==============================] - 0s 129us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 4.0531e-06 - val_acc: 1.0000\n",
            "Epoch 19/20\n",
            "501/501 [==============================] - 0s 133us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 2.7418e-06 - val_acc: 1.0000\n",
            "Epoch 20/20\n",
            "501/501 [==============================] - 0s 144us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 1.3113e-06 - val_acc: 1.0000\n",
            "Train on 501 samples, validate on 1 samples\n",
            "Epoch 1/20\n",
            "501/501 [==============================] - 3s 5ms/step - loss: 2.2522 - acc: 0.1497 - val_loss: 2.1856 - val_acc: 1.0000\n",
            "Epoch 2/20\n",
            "501/501 [==============================] - 0s 85us/step - loss: 2.0112 - acc: 0.4351 - val_loss: 1.7320 - val_acc: 1.0000\n",
            "Epoch 3/20\n",
            "501/501 [==============================] - 0s 80us/step - loss: 1.6583 - acc: 0.5549 - val_loss: 0.9882 - val_acc: 1.0000\n",
            "Epoch 4/20\n",
            "501/501 [==============================] - 0s 74us/step - loss: 1.1823 - acc: 0.7465 - val_loss: 0.4331 - val_acc: 1.0000\n",
            "Epoch 5/20\n",
            "501/501 [==============================] - 0s 85us/step - loss: 0.7761 - acc: 0.8244 - val_loss: 0.1597 - val_acc: 1.0000\n",
            "Epoch 6/20\n",
            "501/501 [==============================] - 0s 80us/step - loss: 0.5461 - acc: 0.8603 - val_loss: 0.0548 - val_acc: 1.0000\n",
            "Epoch 7/20\n",
            "501/501 [==============================] - 0s 81us/step - loss: 0.4009 - acc: 0.8982 - val_loss: 0.0178 - val_acc: 1.0000\n",
            "Epoch 8/20\n",
            "501/501 [==============================] - 0s 87us/step - loss: 0.2964 - acc: 0.9222 - val_loss: 0.0256 - val_acc: 1.0000\n",
            "Epoch 9/20\n",
            "501/501 [==============================] - 0s 78us/step - loss: 0.2472 - acc: 0.9301 - val_loss: 0.0086 - val_acc: 1.0000\n",
            "Epoch 10/20\n",
            "501/501 [==============================] - 0s 80us/step - loss: 0.1816 - acc: 0.9561 - val_loss: 0.0050 - val_acc: 1.0000\n",
            "Epoch 11/20\n",
            "501/501 [==============================] - 0s 82us/step - loss: 0.1338 - acc: 0.9741 - val_loss: 0.0049 - val_acc: 1.0000\n",
            "Epoch 12/20\n",
            "501/501 [==============================] - 0s 80us/step - loss: 0.1005 - acc: 0.9721 - val_loss: 0.0046 - val_acc: 1.0000\n",
            "Epoch 13/20\n",
            "501/501 [==============================] - 0s 86us/step - loss: 0.0781 - acc: 0.9840 - val_loss: 0.0017 - val_acc: 1.0000\n",
            "Epoch 14/20\n",
            "501/501 [==============================] - 0s 81us/step - loss: 0.0580 - acc: 0.9940 - val_loss: 0.0024 - val_acc: 1.0000\n",
            "Epoch 15/20\n",
            "501/501 [==============================] - 0s 80us/step - loss: 0.0397 - acc: 0.9960 - val_loss: 0.0018 - val_acc: 1.0000\n",
            "Epoch 16/20\n",
            "501/501 [==============================] - 0s 82us/step - loss: 0.0326 - acc: 1.0000 - val_loss: 8.0188e-04 - val_acc: 1.0000\n",
            "Epoch 17/20\n",
            "501/501 [==============================] - 0s 85us/step - loss: 0.0242 - acc: 1.0000 - val_loss: 8.2109e-04 - val_acc: 1.0000\n",
            "Epoch 18/20\n",
            "501/501 [==============================] - 0s 89us/step - loss: 0.0194 - acc: 1.0000 - val_loss: 6.9231e-04 - val_acc: 1.0000\n",
            "Epoch 19/20\n",
            "501/501 [==============================] - 0s 89us/step - loss: 0.0155 - acc: 1.0000 - val_loss: 3.6246e-04 - val_acc: 1.0000\n",
            "Epoch 20/20\n",
            "501/501 [==============================] - 0s 80us/step - loss: 0.0120 - acc: 1.0000 - val_loss: 2.4673e-04 - val_acc: 1.0000\n",
            "Train on 501 samples, validate on 1 samples\n",
            "Epoch 1/20\n",
            "501/501 [==============================] - 3s 5ms/step - loss: 2.2730 - acc: 0.1457 - val_loss: 2.1127 - val_acc: 0.0000e+00\n",
            "Epoch 2/20\n",
            "501/501 [==============================] - 0s 66us/step - loss: 2.1494 - acc: 0.1756 - val_loss: 1.8903 - val_acc: 1.0000\n",
            "Epoch 3/20\n",
            "501/501 [==============================] - 0s 58us/step - loss: 1.9859 - acc: 0.3333 - val_loss: 1.4849 - val_acc: 1.0000\n",
            "Epoch 4/20\n",
            "501/501 [==============================] - 0s 51us/step - loss: 1.7640 - acc: 0.4890 - val_loss: 0.8847 - val_acc: 1.0000\n",
            "Epoch 5/20\n",
            "501/501 [==============================] - 0s 55us/step - loss: 1.4840 - acc: 0.6008 - val_loss: 0.4741 - val_acc: 1.0000\n",
            "Epoch 6/20\n",
            "501/501 [==============================] - 0s 59us/step - loss: 1.1864 - acc: 0.7006 - val_loss: 0.2404 - val_acc: 1.0000\n",
            "Epoch 7/20\n",
            "501/501 [==============================] - 0s 62us/step - loss: 0.9292 - acc: 0.7884 - val_loss: 0.0970 - val_acc: 1.0000\n",
            "Epoch 8/20\n",
            "501/501 [==============================] - 0s 61us/step - loss: 0.7126 - acc: 0.8244 - val_loss: 0.0356 - val_acc: 1.0000\n",
            "Epoch 9/20\n",
            "501/501 [==============================] - 0s 57us/step - loss: 0.5485 - acc: 0.8583 - val_loss: 0.0200 - val_acc: 1.0000\n",
            "Epoch 10/20\n",
            "501/501 [==============================] - 0s 62us/step - loss: 0.4242 - acc: 0.9002 - val_loss: 0.0066 - val_acc: 1.0000\n",
            "Epoch 11/20\n",
            "501/501 [==============================] - 0s 60us/step - loss: 0.3342 - acc: 0.9222 - val_loss: 0.0044 - val_acc: 1.0000\n",
            "Epoch 12/20\n",
            "501/501 [==============================] - 0s 57us/step - loss: 0.2729 - acc: 0.9421 - val_loss: 0.0023 - val_acc: 1.0000\n",
            "Epoch 13/20\n",
            "501/501 [==============================] - 0s 60us/step - loss: 0.2165 - acc: 0.9641 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 14/20\n",
            "501/501 [==============================] - 0s 51us/step - loss: 0.1759 - acc: 0.9661 - val_loss: 8.5969e-04 - val_acc: 1.0000\n",
            "Epoch 15/20\n",
            "501/501 [==============================] - 0s 59us/step - loss: 0.1483 - acc: 0.9760 - val_loss: 4.9836e-04 - val_acc: 1.0000\n",
            "Epoch 16/20\n",
            "501/501 [==============================] - 0s 60us/step - loss: 0.1173 - acc: 0.9760 - val_loss: 2.1526e-04 - val_acc: 1.0000\n",
            "Epoch 17/20\n",
            "501/501 [==============================] - 0s 55us/step - loss: 0.0963 - acc: 0.9860 - val_loss: 1.7293e-04 - val_acc: 1.0000\n",
            "Epoch 18/20\n",
            "501/501 [==============================] - 0s 53us/step - loss: 0.0829 - acc: 0.9900 - val_loss: 1.5946e-04 - val_acc: 1.0000\n",
            "Epoch 19/20\n",
            "501/501 [==============================] - 0s 49us/step - loss: 0.0690 - acc: 0.9900 - val_loss: 6.8309e-05 - val_acc: 1.0000\n",
            "Epoch 20/20\n",
            "501/501 [==============================] - 0s 65us/step - loss: 0.0604 - acc: 0.9940 - val_loss: 2.8730e-05 - val_acc: 1.0000\n",
            "Train on 501 samples, validate on 1 samples\n",
            "Epoch 1/20\n",
            "501/501 [==============================] - 3s 5ms/step - loss: 2.3198 - acc: 0.0858 - val_loss: 2.3432 - val_acc: 0.0000e+00\n",
            "Epoch 2/20\n",
            "501/501 [==============================] - 0s 45us/step - loss: 2.2853 - acc: 0.1357 - val_loss: 2.3093 - val_acc: 0.0000e+00\n",
            "Epoch 3/20\n",
            "501/501 [==============================] - 0s 39us/step - loss: 2.2598 - acc: 0.1697 - val_loss: 2.2796 - val_acc: 0.0000e+00\n",
            "Epoch 4/20\n",
            "501/501 [==============================] - 0s 39us/step - loss: 2.2320 - acc: 0.1537 - val_loss: 2.2581 - val_acc: 0.0000e+00\n",
            "Epoch 5/20\n",
            "501/501 [==============================] - 0s 39us/step - loss: 2.2007 - acc: 0.1497 - val_loss: 2.2492 - val_acc: 0.0000e+00\n",
            "Epoch 6/20\n",
            "501/501 [==============================] - 0s 40us/step - loss: 2.1704 - acc: 0.1597 - val_loss: 2.2381 - val_acc: 0.0000e+00\n",
            "Epoch 7/20\n",
            "501/501 [==============================] - 0s 40us/step - loss: 2.1411 - acc: 0.2016 - val_loss: 2.2229 - val_acc: 0.0000e+00\n",
            "Epoch 8/20\n",
            "501/501 [==============================] - 0s 39us/step - loss: 2.1137 - acc: 0.2475 - val_loss: 2.1989 - val_acc: 0.0000e+00\n",
            "Epoch 9/20\n",
            "501/501 [==============================] - 0s 42us/step - loss: 2.0881 - acc: 0.2754 - val_loss: 2.1656 - val_acc: 0.0000e+00\n",
            "Epoch 10/20\n",
            "501/501 [==============================] - 0s 42us/step - loss: 2.0635 - acc: 0.2814 - val_loss: 2.1267 - val_acc: 0.0000e+00\n",
            "Epoch 11/20\n",
            "501/501 [==============================] - 0s 46us/step - loss: 2.0408 - acc: 0.2735 - val_loss: 2.0745 - val_acc: 0.0000e+00\n",
            "Epoch 12/20\n",
            "501/501 [==============================] - 0s 42us/step - loss: 2.0164 - acc: 0.2774 - val_loss: 2.0103 - val_acc: 0.0000e+00\n",
            "Epoch 13/20\n",
            "501/501 [==============================] - 0s 41us/step - loss: 1.9910 - acc: 0.3014 - val_loss: 1.9535 - val_acc: 0.0000e+00\n",
            "Epoch 14/20\n",
            "501/501 [==============================] - 0s 42us/step - loss: 1.9644 - acc: 0.3054 - val_loss: 1.8968 - val_acc: 0.0000e+00\n",
            "Epoch 15/20\n",
            "501/501 [==============================] - 0s 45us/step - loss: 1.9348 - acc: 0.3074 - val_loss: 1.8397 - val_acc: 0.0000e+00\n",
            "Epoch 16/20\n",
            "501/501 [==============================] - 0s 49us/step - loss: 1.9067 - acc: 0.3273 - val_loss: 1.7807 - val_acc: 0.0000e+00\n",
            "Epoch 17/20\n",
            "501/501 [==============================] - 0s 42us/step - loss: 1.8724 - acc: 0.3333 - val_loss: 1.7216 - val_acc: 0.0000e+00\n",
            "Epoch 18/20\n",
            "501/501 [==============================] - 0s 38us/step - loss: 1.8356 - acc: 0.3273 - val_loss: 1.6537 - val_acc: 0.0000e+00\n",
            "Epoch 19/20\n",
            "501/501 [==============================] - 0s 40us/step - loss: 1.7979 - acc: 0.3273 - val_loss: 1.5818 - val_acc: 0.0000e+00\n",
            "Epoch 20/20\n",
            "501/501 [==============================] - 0s 42us/step - loss: 1.7568 - acc: 0.3313 - val_loss: 1.5086 - val_acc: 0.0000e+00\n",
            "Train on 501 samples, validate on 1 samples\n",
            "Epoch 1/20\n",
            "501/501 [==============================] - 3s 6ms/step - loss: 2.1840 - acc: 0.3194 - val_loss: 1.9037 - val_acc: 1.0000\n",
            "Epoch 2/20\n",
            "501/501 [==============================] - 0s 129us/step - loss: 1.6753 - acc: 0.6747 - val_loss: 0.7793 - val_acc: 1.0000\n",
            "Epoch 3/20\n",
            "501/501 [==============================] - 0s 116us/step - loss: 1.0430 - acc: 0.7804 - val_loss: 0.1237 - val_acc: 1.0000\n",
            "Epoch 4/20\n",
            "501/501 [==============================] - 0s 117us/step - loss: 0.5936 - acc: 0.8643 - val_loss: 0.0106 - val_acc: 1.0000\n",
            "Epoch 5/20\n",
            "501/501 [==============================] - 0s 118us/step - loss: 0.3855 - acc: 0.8862 - val_loss: 0.0038 - val_acc: 1.0000\n",
            "Epoch 6/20\n",
            "501/501 [==============================] - 0s 118us/step - loss: 0.2744 - acc: 0.9102 - val_loss: 7.0185e-04 - val_acc: 1.0000\n",
            "Epoch 7/20\n",
            "501/501 [==============================] - 0s 112us/step - loss: 0.1803 - acc: 0.9581 - val_loss: 0.0014 - val_acc: 1.0000\n",
            "Epoch 8/20\n",
            "501/501 [==============================] - 0s 116us/step - loss: 0.1294 - acc: 0.9681 - val_loss: 5.0039e-04 - val_acc: 1.0000\n",
            "Epoch 9/20\n",
            "501/501 [==============================] - 0s 114us/step - loss: 0.0817 - acc: 0.9860 - val_loss: 2.8579e-04 - val_acc: 1.0000\n",
            "Epoch 10/20\n",
            "501/501 [==============================] - 0s 112us/step - loss: 0.0576 - acc: 0.9900 - val_loss: 2.6605e-04 - val_acc: 1.0000\n",
            "Epoch 11/20\n",
            "501/501 [==============================] - 0s 116us/step - loss: 0.0476 - acc: 0.9900 - val_loss: 1.9761e-04 - val_acc: 1.0000\n",
            "Epoch 12/20\n",
            "501/501 [==============================] - 0s 114us/step - loss: 0.0324 - acc: 1.0000 - val_loss: 1.5236e-04 - val_acc: 1.0000\n",
            "Epoch 13/20\n",
            "501/501 [==============================] - 0s 120us/step - loss: 0.0183 - acc: 1.0000 - val_loss: 4.5599e-05 - val_acc: 1.0000\n",
            "Epoch 14/20\n",
            "501/501 [==============================] - 0s 117us/step - loss: 0.0167 - acc: 1.0000 - val_loss: 3.8923e-05 - val_acc: 1.0000\n",
            "Epoch 15/20\n",
            "501/501 [==============================] - 0s 119us/step - loss: 0.0111 - acc: 1.0000 - val_loss: 5.7222e-05 - val_acc: 1.0000\n",
            "Epoch 16/20\n",
            "501/501 [==============================] - 0s 125us/step - loss: 0.0080 - acc: 1.0000 - val_loss: 4.2082e-05 - val_acc: 1.0000\n",
            "Epoch 17/20\n",
            "501/501 [==============================] - 0s 120us/step - loss: 0.0061 - acc: 1.0000 - val_loss: 1.8597e-05 - val_acc: 1.0000\n",
            "Epoch 18/20\n",
            "501/501 [==============================] - 0s 127us/step - loss: 0.0053 - acc: 1.0000 - val_loss: 1.0133e-05 - val_acc: 1.0000\n",
            "Epoch 19/20\n",
            "501/501 [==============================] - 0s 121us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 7.9871e-06 - val_acc: 1.0000\n",
            "Epoch 20/20\n",
            "501/501 [==============================] - 0s 130us/step - loss: 0.0037 - acc: 1.0000 - val_loss: 7.1526e-06 - val_acc: 1.0000\n",
            "Train on 501 samples, validate on 1 samples\n",
            "Epoch 1/20\n",
            "501/501 [==============================] - 3s 6ms/step - loss: 2.2553 - acc: 0.1697 - val_loss: 2.2556 - val_acc: 0.0000e+00\n",
            "Epoch 2/20\n",
            "501/501 [==============================] - 0s 80us/step - loss: 1.9699 - acc: 0.5888 - val_loss: 1.7619 - val_acc: 1.0000\n",
            "Epoch 3/20\n",
            "501/501 [==============================] - 0s 71us/step - loss: 1.5971 - acc: 0.7345 - val_loss: 1.1362 - val_acc: 1.0000\n",
            "Epoch 4/20\n",
            "501/501 [==============================] - 0s 72us/step - loss: 1.1552 - acc: 0.7804 - val_loss: 0.4456 - val_acc: 1.0000\n",
            "Epoch 5/20\n",
            "501/501 [==============================] - 0s 72us/step - loss: 0.7689 - acc: 0.8303 - val_loss: 0.1406 - val_acc: 1.0000\n",
            "Epoch 6/20\n",
            "501/501 [==============================] - 0s 83us/step - loss: 0.5365 - acc: 0.8603 - val_loss: 0.0759 - val_acc: 1.0000\n",
            "Epoch 7/20\n",
            "501/501 [==============================] - 0s 81us/step - loss: 0.4014 - acc: 0.8902 - val_loss: 0.0162 - val_acc: 1.0000\n",
            "Epoch 8/20\n",
            "501/501 [==============================] - 0s 86us/step - loss: 0.3025 - acc: 0.9222 - val_loss: 0.0111 - val_acc: 1.0000\n",
            "Epoch 9/20\n",
            "501/501 [==============================] - 0s 80us/step - loss: 0.2352 - acc: 0.9461 - val_loss: 0.0084 - val_acc: 1.0000\n",
            "Epoch 10/20\n",
            "501/501 [==============================] - 0s 76us/step - loss: 0.1792 - acc: 0.9481 - val_loss: 0.0040 - val_acc: 1.0000\n",
            "Epoch 11/20\n",
            "501/501 [==============================] - 0s 76us/step - loss: 0.1382 - acc: 0.9621 - val_loss: 0.0032 - val_acc: 1.0000\n",
            "Epoch 12/20\n",
            "501/501 [==============================] - 0s 86us/step - loss: 0.1043 - acc: 0.9780 - val_loss: 0.0037 - val_acc: 1.0000\n",
            "Epoch 13/20\n",
            "501/501 [==============================] - 0s 82us/step - loss: 0.0809 - acc: 0.9860 - val_loss: 0.0020 - val_acc: 1.0000\n",
            "Epoch 14/20\n",
            "501/501 [==============================] - 0s 73us/step - loss: 0.0613 - acc: 0.9940 - val_loss: 0.0014 - val_acc: 1.0000\n",
            "Epoch 15/20\n",
            "501/501 [==============================] - 0s 74us/step - loss: 0.0479 - acc: 0.9980 - val_loss: 0.0015 - val_acc: 1.0000\n",
            "Epoch 16/20\n",
            "501/501 [==============================] - 0s 73us/step - loss: 0.0377 - acc: 0.9980 - val_loss: 8.8916e-04 - val_acc: 1.0000\n",
            "Epoch 17/20\n",
            "501/501 [==============================] - 0s 76us/step - loss: 0.0311 - acc: 1.0000 - val_loss: 5.1255e-04 - val_acc: 1.0000\n",
            "Epoch 18/20\n",
            "501/501 [==============================] - 0s 84us/step - loss: 0.0247 - acc: 1.0000 - val_loss: 5.0921e-04 - val_acc: 1.0000\n",
            "Epoch 19/20\n",
            "501/501 [==============================] - 0s 78us/step - loss: 0.0210 - acc: 1.0000 - val_loss: 4.1893e-04 - val_acc: 1.0000\n",
            "Epoch 20/20\n",
            "501/501 [==============================] - 0s 77us/step - loss: 0.0175 - acc: 1.0000 - val_loss: 2.4065e-04 - val_acc: 1.0000\n",
            "Train on 501 samples, validate on 1 samples\n",
            "Epoch 1/20\n",
            "501/501 [==============================] - 3s 6ms/step - loss: 2.2872 - acc: 0.1876 - val_loss: 1.8625 - val_acc: 1.0000\n",
            "Epoch 2/20\n",
            "501/501 [==============================] - 0s 55us/step - loss: 2.1318 - acc: 0.3433 - val_loss: 1.3904 - val_acc: 1.0000\n",
            "Epoch 3/20\n",
            "501/501 [==============================] - 0s 55us/step - loss: 1.9523 - acc: 0.4571 - val_loss: 0.8988 - val_acc: 1.0000\n",
            "Epoch 4/20\n",
            "501/501 [==============================] - 0s 52us/step - loss: 1.7368 - acc: 0.5509 - val_loss: 0.4921 - val_acc: 1.0000\n",
            "Epoch 5/20\n",
            "501/501 [==============================] - 0s 53us/step - loss: 1.4900 - acc: 0.6307 - val_loss: 0.2761 - val_acc: 1.0000\n",
            "Epoch 6/20\n",
            "501/501 [==============================] - 0s 54us/step - loss: 1.2244 - acc: 0.7345 - val_loss: 0.1369 - val_acc: 1.0000\n",
            "Epoch 7/20\n",
            "501/501 [==============================] - 0s 50us/step - loss: 0.9769 - acc: 0.7884 - val_loss: 0.0774 - val_acc: 1.0000\n",
            "Epoch 8/20\n",
            "501/501 [==============================] - 0s 52us/step - loss: 0.7659 - acc: 0.8343 - val_loss: 0.0433 - val_acc: 1.0000\n",
            "Epoch 9/20\n",
            "501/501 [==============================] - 0s 58us/step - loss: 0.6059 - acc: 0.8603 - val_loss: 0.0219 - val_acc: 1.0000\n",
            "Epoch 10/20\n",
            "501/501 [==============================] - 0s 55us/step - loss: 0.4872 - acc: 0.8782 - val_loss: 0.0152 - val_acc: 1.0000\n",
            "Epoch 11/20\n",
            "501/501 [==============================] - 0s 48us/step - loss: 0.3950 - acc: 0.9142 - val_loss: 0.0084 - val_acc: 1.0000\n",
            "Epoch 12/20\n",
            "501/501 [==============================] - 0s 48us/step - loss: 0.3309 - acc: 0.9301 - val_loss: 0.0083 - val_acc: 1.0000\n",
            "Epoch 13/20\n",
            "501/501 [==============================] - 0s 53us/step - loss: 0.2794 - acc: 0.9341 - val_loss: 0.0054 - val_acc: 1.0000\n",
            "Epoch 14/20\n",
            "501/501 [==============================] - 0s 52us/step - loss: 0.2369 - acc: 0.9501 - val_loss: 0.0027 - val_acc: 1.0000\n",
            "Epoch 15/20\n",
            "501/501 [==============================] - 0s 68us/step - loss: 0.2039 - acc: 0.9501 - val_loss: 0.0034 - val_acc: 1.0000\n",
            "Epoch 16/20\n",
            "501/501 [==============================] - 0s 60us/step - loss: 0.1778 - acc: 0.9661 - val_loss: 0.0033 - val_acc: 1.0000\n",
            "Epoch 17/20\n",
            "501/501 [==============================] - 0s 52us/step - loss: 0.1474 - acc: 0.9741 - val_loss: 0.0012 - val_acc: 1.0000\n",
            "Epoch 18/20\n",
            "501/501 [==============================] - 0s 53us/step - loss: 0.1288 - acc: 0.9780 - val_loss: 0.0015 - val_acc: 1.0000\n",
            "Epoch 19/20\n",
            "501/501 [==============================] - 0s 52us/step - loss: 0.1092 - acc: 0.9780 - val_loss: 0.0016 - val_acc: 1.0000\n",
            "Epoch 20/20\n",
            "501/501 [==============================] - 0s 58us/step - loss: 0.0931 - acc: 0.9880 - val_loss: 6.4793e-04 - val_acc: 1.0000\n",
            "Train on 501 samples, validate on 1 samples\n",
            "Epoch 1/20\n",
            "501/501 [==============================] - 3s 6ms/step - loss: 2.2921 - acc: 0.1238 - val_loss: 2.2613 - val_acc: 0.0000e+00\n",
            "Epoch 2/20\n",
            "501/501 [==============================] - 0s 51us/step - loss: 2.2298 - acc: 0.1437 - val_loss: 2.1276 - val_acc: 0.0000e+00\n",
            "Epoch 3/20\n",
            "501/501 [==============================] - 0s 45us/step - loss: 2.1786 - acc: 0.1517 - val_loss: 2.0462 - val_acc: 0.0000e+00\n",
            "Epoch 4/20\n",
            "501/501 [==============================] - 0s 42us/step - loss: 2.1272 - acc: 0.1657 - val_loss: 1.9751 - val_acc: 0.0000e+00\n",
            "Epoch 5/20\n",
            "501/501 [==============================] - 0s 45us/step - loss: 2.0737 - acc: 0.1976 - val_loss: 1.8893 - val_acc: 0.0000e+00\n",
            "Epoch 6/20\n",
            "501/501 [==============================] - 0s 46us/step - loss: 2.0159 - acc: 0.2355 - val_loss: 1.7931 - val_acc: 0.0000e+00\n",
            "Epoch 7/20\n",
            "501/501 [==============================] - 0s 45us/step - loss: 1.9541 - acc: 0.2695 - val_loss: 1.7071 - val_acc: 0.0000e+00\n",
            "Epoch 8/20\n",
            "501/501 [==============================] - 0s 46us/step - loss: 1.8949 - acc: 0.3593 - val_loss: 1.5957 - val_acc: 0.0000e+00\n",
            "Epoch 9/20\n",
            "501/501 [==============================] - 0s 53us/step - loss: 1.8351 - acc: 0.4032 - val_loss: 1.5166 - val_acc: 1.0000\n",
            "Epoch 10/20\n",
            "501/501 [==============================] - 0s 55us/step - loss: 1.7761 - acc: 0.4471 - val_loss: 1.4235 - val_acc: 1.0000\n",
            "Epoch 11/20\n",
            "501/501 [==============================] - 0s 50us/step - loss: 1.7141 - acc: 0.5010 - val_loss: 1.3324 - val_acc: 1.0000\n",
            "Epoch 12/20\n",
            "501/501 [==============================] - 0s 45us/step - loss: 1.6591 - acc: 0.5509 - val_loss: 1.1985 - val_acc: 1.0000\n",
            "Epoch 13/20\n",
            "501/501 [==============================] - 0s 49us/step - loss: 1.5967 - acc: 0.5948 - val_loss: 1.1034 - val_acc: 1.0000\n",
            "Epoch 14/20\n",
            "501/501 [==============================] - 0s 45us/step - loss: 1.5395 - acc: 0.6248 - val_loss: 1.0034 - val_acc: 1.0000\n",
            "Epoch 15/20\n",
            "501/501 [==============================] - 0s 45us/step - loss: 1.4813 - acc: 0.6547 - val_loss: 0.8899 - val_acc: 1.0000\n",
            "Epoch 16/20\n",
            "501/501 [==============================] - 0s 47us/step - loss: 1.4262 - acc: 0.6587 - val_loss: 0.7839 - val_acc: 1.0000\n",
            "Epoch 17/20\n",
            "501/501 [==============================] - 0s 52us/step - loss: 1.3732 - acc: 0.6786 - val_loss: 0.6840 - val_acc: 1.0000\n",
            "Epoch 18/20\n",
            "501/501 [==============================] - 0s 44us/step - loss: 1.3181 - acc: 0.7006 - val_loss: 0.6256 - val_acc: 1.0000\n",
            "Epoch 19/20\n",
            "501/501 [==============================] - 0s 48us/step - loss: 1.2655 - acc: 0.6986 - val_loss: 0.5564 - val_acc: 1.0000\n",
            "Epoch 20/20\n",
            "501/501 [==============================] - 0s 45us/step - loss: 1.2138 - acc: 0.7086 - val_loss: 0.4886 - val_acc: 1.0000\n",
            "Train on 501 samples, validate on 1 samples\n",
            "Epoch 1/20\n",
            "501/501 [==============================] - 3s 6ms/step - loss: 2.1794 - acc: 0.2216 - val_loss: 1.5256 - val_acc: 1.0000\n",
            "Epoch 2/20\n",
            "501/501 [==============================] - 0s 112us/step - loss: 1.6172 - acc: 0.6707 - val_loss: 0.6321 - val_acc: 1.0000\n",
            "Epoch 3/20\n",
            "501/501 [==============================] - 0s 95us/step - loss: 1.0749 - acc: 0.7924 - val_loss: 0.1266 - val_acc: 1.0000\n",
            "Epoch 4/20\n",
            "501/501 [==============================] - 0s 101us/step - loss: 0.6751 - acc: 0.8623 - val_loss: 0.0358 - val_acc: 1.0000\n",
            "Epoch 5/20\n",
            "501/501 [==============================] - 0s 98us/step - loss: 0.4551 - acc: 0.8822 - val_loss: 0.0074 - val_acc: 1.0000\n",
            "Epoch 6/20\n",
            "501/501 [==============================] - 0s 100us/step - loss: 0.3245 - acc: 0.9242 - val_loss: 0.0019 - val_acc: 1.0000\n",
            "Epoch 7/20\n",
            "501/501 [==============================] - 0s 98us/step - loss: 0.2451 - acc: 0.9401 - val_loss: 0.0019 - val_acc: 1.0000\n",
            "Epoch 8/20\n",
            "501/501 [==============================] - 0s 95us/step - loss: 0.1717 - acc: 0.9681 - val_loss: 6.5151e-04 - val_acc: 1.0000\n",
            "Epoch 9/20\n",
            "501/501 [==============================] - 0s 104us/step - loss: 0.1349 - acc: 0.9741 - val_loss: 4.3885e-04 - val_acc: 1.0000\n",
            "Epoch 10/20\n",
            "501/501 [==============================] - 0s 93us/step - loss: 0.0983 - acc: 0.9840 - val_loss: 3.6401e-04 - val_acc: 1.0000\n",
            "Epoch 11/20\n",
            "501/501 [==============================] - 0s 109us/step - loss: 0.0745 - acc: 0.9920 - val_loss: 1.4580e-04 - val_acc: 1.0000\n",
            "Epoch 12/20\n",
            "501/501 [==============================] - 0s 99us/step - loss: 0.0545 - acc: 0.9940 - val_loss: 7.5760e-05 - val_acc: 1.0000\n",
            "Epoch 13/20\n",
            "501/501 [==============================] - 0s 104us/step - loss: 0.0420 - acc: 0.9980 - val_loss: 9.0842e-05 - val_acc: 1.0000\n",
            "Epoch 14/20\n",
            "501/501 [==============================] - 0s 106us/step - loss: 0.0334 - acc: 1.0000 - val_loss: 5.5017e-05 - val_acc: 1.0000\n",
            "Epoch 15/20\n",
            "501/501 [==============================] - 0s 100us/step - loss: 0.0255 - acc: 1.0000 - val_loss: 5.2334e-05 - val_acc: 1.0000\n",
            "Epoch 16/20\n",
            "501/501 [==============================] - 0s 103us/step - loss: 0.0209 - acc: 1.0000 - val_loss: 3.1353e-05 - val_acc: 1.0000\n",
            "Epoch 17/20\n",
            "501/501 [==============================] - 0s 108us/step - loss: 0.0174 - acc: 1.0000 - val_loss: 1.6928e-05 - val_acc: 1.0000\n",
            "Epoch 18/20\n",
            "501/501 [==============================] - 0s 105us/step - loss: 0.0149 - acc: 1.0000 - val_loss: 1.1563e-05 - val_acc: 1.0000\n",
            "Epoch 19/20\n",
            "501/501 [==============================] - 0s 104us/step - loss: 0.0127 - acc: 1.0000 - val_loss: 1.4067e-05 - val_acc: 1.0000\n",
            "Epoch 20/20\n",
            "501/501 [==============================] - 0s 97us/step - loss: 0.0110 - acc: 1.0000 - val_loss: 1.0729e-05 - val_acc: 1.0000\n",
            "Train on 501 samples, validate on 1 samples\n",
            "Epoch 1/20\n",
            "501/501 [==============================] - 3s 6ms/step - loss: 2.2837 - acc: 0.1257 - val_loss: 1.9112 - val_acc: 1.0000\n",
            "Epoch 2/20\n",
            "501/501 [==============================] - 0s 75us/step - loss: 1.9616 - acc: 0.4810 - val_loss: 1.4474 - val_acc: 1.0000\n",
            "Epoch 3/20\n",
            "501/501 [==============================] - 0s 77us/step - loss: 1.6170 - acc: 0.7146 - val_loss: 0.8688 - val_acc: 1.0000\n",
            "Epoch 4/20\n",
            "501/501 [==============================] - 0s 65us/step - loss: 1.2479 - acc: 0.8044 - val_loss: 0.4269 - val_acc: 1.0000\n",
            "Epoch 5/20\n",
            "501/501 [==============================] - 0s 68us/step - loss: 0.9200 - acc: 0.8224 - val_loss: 0.1793 - val_acc: 1.0000\n",
            "Epoch 6/20\n",
            "501/501 [==============================] - 0s 74us/step - loss: 0.6828 - acc: 0.8583 - val_loss: 0.0922 - val_acc: 1.0000\n",
            "Epoch 7/20\n",
            "501/501 [==============================] - 0s 80us/step - loss: 0.5151 - acc: 0.8942 - val_loss: 0.0393 - val_acc: 1.0000\n",
            "Epoch 8/20\n",
            "501/501 [==============================] - 0s 74us/step - loss: 0.4029 - acc: 0.9182 - val_loss: 0.0167 - val_acc: 1.0000\n",
            "Epoch 9/20\n",
            "501/501 [==============================] - 0s 63us/step - loss: 0.3256 - acc: 0.9321 - val_loss: 0.0125 - val_acc: 1.0000\n",
            "Epoch 10/20\n",
            "501/501 [==============================] - 0s 68us/step - loss: 0.2668 - acc: 0.9541 - val_loss: 0.0079 - val_acc: 1.0000\n",
            "Epoch 11/20\n",
            "501/501 [==============================] - 0s 67us/step - loss: 0.2182 - acc: 0.9561 - val_loss: 0.0047 - val_acc: 1.0000\n",
            "Epoch 12/20\n",
            "501/501 [==============================] - 0s 67us/step - loss: 0.1811 - acc: 0.9661 - val_loss: 0.0042 - val_acc: 1.0000\n",
            "Epoch 13/20\n",
            "501/501 [==============================] - 0s 73us/step - loss: 0.1531 - acc: 0.9721 - val_loss: 0.0028 - val_acc: 1.0000\n",
            "Epoch 14/20\n",
            "501/501 [==============================] - 0s 78us/step - loss: 0.1301 - acc: 0.9820 - val_loss: 0.0025 - val_acc: 1.0000\n",
            "Epoch 15/20\n",
            "501/501 [==============================] - 0s 69us/step - loss: 0.1067 - acc: 0.9900 - val_loss: 0.0015 - val_acc: 1.0000\n",
            "Epoch 16/20\n",
            "501/501 [==============================] - 0s 68us/step - loss: 0.0904 - acc: 0.9920 - val_loss: 0.0014 - val_acc: 1.0000\n",
            "Epoch 17/20\n",
            "501/501 [==============================] - 0s 83us/step - loss: 0.0778 - acc: 0.9920 - val_loss: 0.0010 - val_acc: 1.0000\n",
            "Epoch 18/20\n",
            "501/501 [==============================] - 0s 81us/step - loss: 0.0668 - acc: 0.9960 - val_loss: 6.6809e-04 - val_acc: 1.0000\n",
            "Epoch 19/20\n",
            "501/501 [==============================] - 0s 74us/step - loss: 0.0574 - acc: 0.9960 - val_loss: 6.0612e-04 - val_acc: 1.0000\n",
            "Epoch 20/20\n",
            "501/501 [==============================] - 0s 74us/step - loss: 0.0497 - acc: 0.9960 - val_loss: 5.6903e-04 - val_acc: 1.0000\n",
            "Train on 501 samples, validate on 1 samples\n",
            "Epoch 1/20\n",
            "501/501 [==============================] - 3s 6ms/step - loss: 2.2786 - acc: 0.1198 - val_loss: 1.9781 - val_acc: 1.0000\n",
            "Epoch 2/20\n",
            "501/501 [==============================] - 0s 53us/step - loss: 2.1009 - acc: 0.3473 - val_loss: 1.6995 - val_acc: 1.0000\n",
            "Epoch 3/20\n",
            "501/501 [==============================] - 0s 50us/step - loss: 1.9252 - acc: 0.4830 - val_loss: 1.3865 - val_acc: 1.0000\n",
            "Epoch 4/20\n",
            "501/501 [==============================] - 0s 53us/step - loss: 1.7116 - acc: 0.6188 - val_loss: 1.0603 - val_acc: 1.0000\n",
            "Epoch 5/20\n",
            "501/501 [==============================] - 0s 52us/step - loss: 1.4785 - acc: 0.7425 - val_loss: 0.7005 - val_acc: 1.0000\n",
            "Epoch 6/20\n",
            "501/501 [==============================] - 0s 54us/step - loss: 1.2385 - acc: 0.7904 - val_loss: 0.3869 - val_acc: 1.0000\n",
            "Epoch 7/20\n",
            "501/501 [==============================] - 0s 55us/step - loss: 1.0240 - acc: 0.8224 - val_loss: 0.1909 - val_acc: 1.0000\n",
            "Epoch 8/20\n",
            "501/501 [==============================] - 0s 52us/step - loss: 0.8326 - acc: 0.8483 - val_loss: 0.1089 - val_acc: 1.0000\n",
            "Epoch 9/20\n",
            "501/501 [==============================] - 0s 53us/step - loss: 0.6758 - acc: 0.8782 - val_loss: 0.0670 - val_acc: 1.0000\n",
            "Epoch 10/20\n",
            "501/501 [==============================] - 0s 59us/step - loss: 0.5613 - acc: 0.8922 - val_loss: 0.0330 - val_acc: 1.0000\n",
            "Epoch 11/20\n",
            "501/501 [==============================] - 0s 59us/step - loss: 0.4692 - acc: 0.9002 - val_loss: 0.0175 - val_acc: 1.0000\n",
            "Epoch 12/20\n",
            "501/501 [==============================] - 0s 55us/step - loss: 0.4018 - acc: 0.9102 - val_loss: 0.0128 - val_acc: 1.0000\n",
            "Epoch 13/20\n",
            "501/501 [==============================] - 0s 58us/step - loss: 0.3469 - acc: 0.9242 - val_loss: 0.0077 - val_acc: 1.0000\n",
            "Epoch 14/20\n",
            "501/501 [==============================] - 0s 58us/step - loss: 0.3046 - acc: 0.9361 - val_loss: 0.0059 - val_acc: 1.0000\n",
            "Epoch 15/20\n",
            "501/501 [==============================] - 0s 58us/step - loss: 0.2652 - acc: 0.9481 - val_loss: 0.0046 - val_acc: 1.0000\n",
            "Epoch 16/20\n",
            "501/501 [==============================] - 0s 50us/step - loss: 0.2357 - acc: 0.9621 - val_loss: 0.0039 - val_acc: 1.0000\n",
            "Epoch 17/20\n",
            "501/501 [==============================] - 0s 53us/step - loss: 0.2106 - acc: 0.9681 - val_loss: 0.0032 - val_acc: 1.0000\n",
            "Epoch 18/20\n",
            "501/501 [==============================] - 0s 53us/step - loss: 0.1862 - acc: 0.9721 - val_loss: 0.0025 - val_acc: 1.0000\n",
            "Epoch 19/20\n",
            "501/501 [==============================] - 0s 45us/step - loss: 0.1665 - acc: 0.9760 - val_loss: 0.0022 - val_acc: 1.0000\n",
            "Epoch 20/20\n",
            "501/501 [==============================] - 0s 47us/step - loss: 0.1504 - acc: 0.9760 - val_loss: 0.0018 - val_acc: 1.0000\n",
            "Train on 501 samples, validate on 1 samples\n",
            "Epoch 1/20\n",
            "501/501 [==============================] - 3s 7ms/step - loss: 2.3362 - acc: 0.1657 - val_loss: 1.9207 - val_acc: 1.0000\n",
            "Epoch 2/20\n",
            "501/501 [==============================] - 0s 50us/step - loss: 2.2538 - acc: 0.2236 - val_loss: 1.7099 - val_acc: 1.0000\n",
            "Epoch 3/20\n",
            "501/501 [==============================] - 0s 44us/step - loss: 2.1792 - acc: 0.2315 - val_loss: 1.5321 - val_acc: 1.0000\n",
            "Epoch 4/20\n",
            "501/501 [==============================] - 0s 42us/step - loss: 2.0998 - acc: 0.2635 - val_loss: 1.3446 - val_acc: 1.0000\n",
            "Epoch 5/20\n",
            "501/501 [==============================] - 0s 45us/step - loss: 2.0136 - acc: 0.2934 - val_loss: 1.1553 - val_acc: 1.0000\n",
            "Epoch 6/20\n",
            "501/501 [==============================] - 0s 45us/step - loss: 1.9244 - acc: 0.3134 - val_loss: 0.9675 - val_acc: 1.0000\n",
            "Epoch 7/20\n",
            "501/501 [==============================] - 0s 46us/step - loss: 1.8382 - acc: 0.3313 - val_loss: 0.7969 - val_acc: 1.0000\n",
            "Epoch 8/20\n",
            "501/501 [==============================] - 0s 44us/step - loss: 1.7539 - acc: 0.3613 - val_loss: 0.6671 - val_acc: 1.0000\n",
            "Epoch 9/20\n",
            "501/501 [==============================] - 0s 43us/step - loss: 1.6779 - acc: 0.3812 - val_loss: 0.5424 - val_acc: 1.0000\n",
            "Epoch 10/20\n",
            "501/501 [==============================] - 0s 49us/step - loss: 1.6023 - acc: 0.4152 - val_loss: 0.4434 - val_acc: 1.0000\n",
            "Epoch 11/20\n",
            "501/501 [==============================] - 0s 50us/step - loss: 1.5302 - acc: 0.4810 - val_loss: 0.3727 - val_acc: 1.0000\n",
            "Epoch 12/20\n",
            "501/501 [==============================] - 0s 60us/step - loss: 1.4631 - acc: 0.5429 - val_loss: 0.3152 - val_acc: 1.0000\n",
            "Epoch 13/20\n",
            "501/501 [==============================] - 0s 44us/step - loss: 1.3954 - acc: 0.5768 - val_loss: 0.2596 - val_acc: 1.0000\n",
            "Epoch 14/20\n",
            "501/501 [==============================] - 0s 45us/step - loss: 1.3314 - acc: 0.6248 - val_loss: 0.2191 - val_acc: 1.0000\n",
            "Epoch 15/20\n",
            "501/501 [==============================] - 0s 46us/step - loss: 1.2698 - acc: 0.6487 - val_loss: 0.1913 - val_acc: 1.0000\n",
            "Epoch 16/20\n",
            "501/501 [==============================] - 0s 44us/step - loss: 1.2104 - acc: 0.6687 - val_loss: 0.1637 - val_acc: 1.0000\n",
            "Epoch 17/20\n",
            "501/501 [==============================] - 0s 42us/step - loss: 1.1547 - acc: 0.7006 - val_loss: 0.1443 - val_acc: 1.0000\n",
            "Epoch 18/20\n",
            "501/501 [==============================] - 0s 58us/step - loss: 1.1004 - acc: 0.7186 - val_loss: 0.1296 - val_acc: 1.0000\n",
            "Epoch 19/20\n",
            "501/501 [==============================] - 0s 48us/step - loss: 1.0488 - acc: 0.7345 - val_loss: 0.1113 - val_acc: 1.0000\n",
            "Epoch 20/20\n",
            "501/501 [==============================] - 0s 52us/step - loss: 1.0011 - acc: 0.7505 - val_loss: 0.1007 - val_acc: 1.0000\n",
            "Train on 501 samples, validate on 1 samples\n",
            "Epoch 1/20\n",
            "501/501 [==============================] - 3s 7ms/step - loss: 2.1673 - acc: 0.2435 - val_loss: 1.4788 - val_acc: 1.0000\n",
            "Epoch 2/20\n",
            "501/501 [==============================] - 0s 97us/step - loss: 1.5509 - acc: 0.6806 - val_loss: 0.6778 - val_acc: 1.0000\n",
            "Epoch 3/20\n",
            "501/501 [==============================] - 0s 81us/step - loss: 1.1056 - acc: 0.8104 - val_loss: 0.2336 - val_acc: 1.0000\n",
            "Epoch 4/20\n",
            "501/501 [==============================] - 0s 88us/step - loss: 0.7935 - acc: 0.8723 - val_loss: 0.0979 - val_acc: 1.0000\n",
            "Epoch 5/20\n",
            "501/501 [==============================] - 0s 86us/step - loss: 0.6025 - acc: 0.8842 - val_loss: 0.0487 - val_acc: 1.0000\n",
            "Epoch 6/20\n",
            "501/501 [==============================] - 0s 85us/step - loss: 0.4699 - acc: 0.8982 - val_loss: 0.0200 - val_acc: 1.0000\n",
            "Epoch 7/20\n",
            "501/501 [==============================] - 0s 84us/step - loss: 0.3839 - acc: 0.9222 - val_loss: 0.0104 - val_acc: 1.0000\n",
            "Epoch 8/20\n",
            "501/501 [==============================] - 0s 78us/step - loss: 0.3186 - acc: 0.9321 - val_loss: 0.0092 - val_acc: 1.0000\n",
            "Epoch 9/20\n",
            "501/501 [==============================] - 0s 88us/step - loss: 0.2703 - acc: 0.9541 - val_loss: 0.0065 - val_acc: 1.0000\n",
            "Epoch 10/20\n",
            "501/501 [==============================] - 0s 81us/step - loss: 0.2296 - acc: 0.9681 - val_loss: 0.0045 - val_acc: 1.0000\n",
            "Epoch 11/20\n",
            "501/501 [==============================] - 0s 81us/step - loss: 0.2012 - acc: 0.9721 - val_loss: 0.0043 - val_acc: 1.0000\n",
            "Epoch 12/20\n",
            "501/501 [==============================] - 0s 73us/step - loss: 0.1751 - acc: 0.9760 - val_loss: 0.0037 - val_acc: 1.0000\n",
            "Epoch 13/20\n",
            "501/501 [==============================] - 0s 79us/step - loss: 0.1541 - acc: 0.9780 - val_loss: 0.0027 - val_acc: 1.0000\n",
            "Epoch 14/20\n",
            "501/501 [==============================] - 0s 77us/step - loss: 0.1364 - acc: 0.9860 - val_loss: 0.0018 - val_acc: 1.0000\n",
            "Epoch 15/20\n",
            "501/501 [==============================] - 0s 76us/step - loss: 0.1207 - acc: 0.9900 - val_loss: 0.0018 - val_acc: 1.0000\n",
            "Epoch 16/20\n",
            "501/501 [==============================] - 0s 83us/step - loss: 0.1074 - acc: 0.9900 - val_loss: 0.0018 - val_acc: 1.0000\n",
            "Epoch 17/20\n",
            "501/501 [==============================] - 0s 78us/step - loss: 0.0961 - acc: 0.9880 - val_loss: 0.0013 - val_acc: 1.0000\n",
            "Epoch 18/20\n",
            "501/501 [==============================] - 0s 92us/step - loss: 0.0859 - acc: 0.9920 - val_loss: 9.2931e-04 - val_acc: 1.0000\n",
            "Epoch 19/20\n",
            "501/501 [==============================] - 0s 77us/step - loss: 0.0773 - acc: 0.9980 - val_loss: 8.7305e-04 - val_acc: 1.0000\n",
            "Epoch 20/20\n",
            "501/501 [==============================] - 0s 81us/step - loss: 0.0700 - acc: 0.9980 - val_loss: 7.6138e-04 - val_acc: 1.0000\n",
            "Train on 501 samples, validate on 1 samples\n",
            "Epoch 1/20\n",
            "501/501 [==============================] - 3s 7ms/step - loss: 2.1909 - acc: 0.1976 - val_loss: 1.6110 - val_acc: 1.0000\n",
            "Epoch 2/20\n",
            "501/501 [==============================] - 0s 72us/step - loss: 1.7443 - acc: 0.6287 - val_loss: 1.0655 - val_acc: 1.0000\n",
            "Epoch 3/20\n",
            "501/501 [==============================] - 0s 63us/step - loss: 1.3868 - acc: 0.7565 - val_loss: 0.6087 - val_acc: 1.0000\n",
            "Epoch 4/20\n",
            "501/501 [==============================] - 0s 65us/step - loss: 1.0814 - acc: 0.7984 - val_loss: 0.2855 - val_acc: 1.0000\n",
            "Epoch 5/20\n",
            "501/501 [==============================] - 0s 65us/step - loss: 0.8467 - acc: 0.8363 - val_loss: 0.1445 - val_acc: 1.0000\n",
            "Epoch 6/20\n",
            "501/501 [==============================] - 0s 71us/step - loss: 0.6802 - acc: 0.8743 - val_loss: 0.0751 - val_acc: 1.0000\n",
            "Epoch 7/20\n",
            "501/501 [==============================] - 0s 65us/step - loss: 0.5635 - acc: 0.8942 - val_loss: 0.0460 - val_acc: 1.0000\n",
            "Epoch 8/20\n",
            "501/501 [==============================] - 0s 62us/step - loss: 0.4757 - acc: 0.9062 - val_loss: 0.0297 - val_acc: 1.0000\n",
            "Epoch 9/20\n",
            "501/501 [==============================] - 0s 65us/step - loss: 0.4118 - acc: 0.9182 - val_loss: 0.0191 - val_acc: 1.0000\n",
            "Epoch 10/20\n",
            "501/501 [==============================] - 0s 63us/step - loss: 0.3606 - acc: 0.9321 - val_loss: 0.0121 - val_acc: 1.0000\n",
            "Epoch 11/20\n",
            "501/501 [==============================] - 0s 64us/step - loss: 0.3202 - acc: 0.9441 - val_loss: 0.0096 - val_acc: 1.0000\n",
            "Epoch 12/20\n",
            "501/501 [==============================] - 0s 63us/step - loss: 0.2844 - acc: 0.9521 - val_loss: 0.0081 - val_acc: 1.0000\n",
            "Epoch 13/20\n",
            "501/501 [==============================] - 0s 65us/step - loss: 0.2558 - acc: 0.9601 - val_loss: 0.0067 - val_acc: 1.0000\n",
            "Epoch 14/20\n",
            "501/501 [==============================] - 0s 70us/step - loss: 0.2319 - acc: 0.9641 - val_loss: 0.0068 - val_acc: 1.0000\n",
            "Epoch 15/20\n",
            "501/501 [==============================] - 0s 63us/step - loss: 0.2104 - acc: 0.9681 - val_loss: 0.0048 - val_acc: 1.0000\n",
            "Epoch 16/20\n",
            "501/501 [==============================] - 0s 67us/step - loss: 0.1912 - acc: 0.9721 - val_loss: 0.0038 - val_acc: 1.0000\n",
            "Epoch 17/20\n",
            "501/501 [==============================] - 0s 60us/step - loss: 0.1745 - acc: 0.9741 - val_loss: 0.0034 - val_acc: 1.0000\n",
            "Epoch 18/20\n",
            "501/501 [==============================] - 0s 67us/step - loss: 0.1606 - acc: 0.9800 - val_loss: 0.0031 - val_acc: 1.0000\n",
            "Epoch 19/20\n",
            "501/501 [==============================] - 0s 67us/step - loss: 0.1467 - acc: 0.9840 - val_loss: 0.0027 - val_acc: 1.0000\n",
            "Epoch 20/20\n",
            "501/501 [==============================] - 0s 63us/step - loss: 0.1354 - acc: 0.9840 - val_loss: 0.0024 - val_acc: 1.0000\n",
            "Train on 501 samples, validate on 1 samples\n",
            "Epoch 1/20\n",
            "501/501 [==============================] - 3s 7ms/step - loss: 2.2895 - acc: 0.1178 - val_loss: 2.2010 - val_acc: 0.0000e+00\n",
            "Epoch 2/20\n",
            "501/501 [==============================] - 0s 53us/step - loss: 1.9468 - acc: 0.4511 - val_loss: 1.7855 - val_acc: 1.0000\n",
            "Epoch 3/20\n",
            "501/501 [==============================] - 0s 48us/step - loss: 1.6703 - acc: 0.6287 - val_loss: 1.3479 - val_acc: 1.0000\n",
            "Epoch 4/20\n",
            "501/501 [==============================] - 0s 45us/step - loss: 1.4098 - acc: 0.7186 - val_loss: 0.9280 - val_acc: 1.0000\n",
            "Epoch 5/20\n",
            "501/501 [==============================] - 0s 49us/step - loss: 1.1780 - acc: 0.7645 - val_loss: 0.6202 - val_acc: 1.0000\n",
            "Epoch 6/20\n",
            "501/501 [==============================] - 0s 53us/step - loss: 0.9831 - acc: 0.8303 - val_loss: 0.4401 - val_acc: 1.0000\n",
            "Epoch 7/20\n",
            "501/501 [==============================] - 0s 49us/step - loss: 0.8330 - acc: 0.8563 - val_loss: 0.3175 - val_acc: 1.0000\n",
            "Epoch 8/20\n",
            "501/501 [==============================] - 0s 48us/step - loss: 0.7169 - acc: 0.8802 - val_loss: 0.2263 - val_acc: 1.0000\n",
            "Epoch 9/20\n",
            "501/501 [==============================] - 0s 45us/step - loss: 0.6264 - acc: 0.8842 - val_loss: 0.1730 - val_acc: 1.0000\n",
            "Epoch 10/20\n",
            "501/501 [==============================] - 0s 53us/step - loss: 0.5555 - acc: 0.9002 - val_loss: 0.1290 - val_acc: 1.0000\n",
            "Epoch 11/20\n",
            "501/501 [==============================] - 0s 46us/step - loss: 0.4975 - acc: 0.9062 - val_loss: 0.0992 - val_acc: 1.0000\n",
            "Epoch 12/20\n",
            "501/501 [==============================] - 0s 51us/step - loss: 0.4506 - acc: 0.9102 - val_loss: 0.0788 - val_acc: 1.0000\n",
            "Epoch 13/20\n",
            "501/501 [==============================] - 0s 52us/step - loss: 0.4105 - acc: 0.9222 - val_loss: 0.0620 - val_acc: 1.0000\n",
            "Epoch 14/20\n",
            "501/501 [==============================] - 0s 50us/step - loss: 0.3762 - acc: 0.9301 - val_loss: 0.0536 - val_acc: 1.0000\n",
            "Epoch 15/20\n",
            "501/501 [==============================] - 0s 48us/step - loss: 0.3461 - acc: 0.9381 - val_loss: 0.0499 - val_acc: 1.0000\n",
            "Epoch 16/20\n",
            "501/501 [==============================] - 0s 50us/step - loss: 0.3220 - acc: 0.9381 - val_loss: 0.0464 - val_acc: 1.0000\n",
            "Epoch 17/20\n",
            "501/501 [==============================] - 0s 66us/step - loss: 0.2970 - acc: 0.9441 - val_loss: 0.0374 - val_acc: 1.0000\n",
            "Epoch 18/20\n",
            "501/501 [==============================] - 0s 62us/step - loss: 0.2772 - acc: 0.9501 - val_loss: 0.0297 - val_acc: 1.0000\n",
            "Epoch 19/20\n",
            "501/501 [==============================] - 0s 49us/step - loss: 0.2595 - acc: 0.9601 - val_loss: 0.0246 - val_acc: 1.0000\n",
            "Epoch 20/20\n",
            "501/501 [==============================] - 0s 49us/step - loss: 0.2408 - acc: 0.9641 - val_loss: 0.0224 - val_acc: 1.0000\n",
            "Train on 501 samples, validate on 1 samples\n",
            "Epoch 1/20\n",
            "501/501 [==============================] - 3s 7ms/step - loss: 2.3625 - acc: 0.1138 - val_loss: 2.3045 - val_acc: 0.0000e+00\n",
            "Epoch 2/20\n",
            "501/501 [==============================] - 0s 47us/step - loss: 2.2692 - acc: 0.1776 - val_loss: 2.3166 - val_acc: 0.0000e+00\n",
            "Epoch 3/20\n",
            "501/501 [==============================] - 0s 44us/step - loss: 2.1990 - acc: 0.2295 - val_loss: 2.3282 - val_acc: 0.0000e+00\n",
            "Epoch 4/20\n",
            "501/501 [==============================] - 0s 42us/step - loss: 2.1250 - acc: 0.2715 - val_loss: 2.3334 - val_acc: 0.0000e+00\n",
            "Epoch 5/20\n",
            "501/501 [==============================] - 0s 44us/step - loss: 2.0411 - acc: 0.2974 - val_loss: 2.3370 - val_acc: 0.0000e+00\n",
            "Epoch 6/20\n",
            "501/501 [==============================] - 0s 42us/step - loss: 1.9574 - acc: 0.3154 - val_loss: 2.2988 - val_acc: 0.0000e+00\n",
            "Epoch 7/20\n",
            "501/501 [==============================] - 0s 42us/step - loss: 1.8660 - acc: 0.3393 - val_loss: 2.2545 - val_acc: 0.0000e+00\n",
            "Epoch 8/20\n",
            "501/501 [==============================] - 0s 48us/step - loss: 1.7837 - acc: 0.3513 - val_loss: 2.2034 - val_acc: 0.0000e+00\n",
            "Epoch 9/20\n",
            "501/501 [==============================] - 0s 42us/step - loss: 1.7107 - acc: 0.3633 - val_loss: 2.1521 - val_acc: 0.0000e+00\n",
            "Epoch 10/20\n",
            "501/501 [==============================] - 0s 41us/step - loss: 1.6402 - acc: 0.3752 - val_loss: 2.1079 - val_acc: 0.0000e+00\n",
            "Epoch 11/20\n",
            "501/501 [==============================] - 0s 43us/step - loss: 1.5740 - acc: 0.4032 - val_loss: 2.0663 - val_acc: 0.0000e+00\n",
            "Epoch 12/20\n",
            "501/501 [==============================] - 0s 42us/step - loss: 1.5126 - acc: 0.4391 - val_loss: 2.0279 - val_acc: 0.0000e+00\n",
            "Epoch 13/20\n",
            "501/501 [==============================] - 0s 42us/step - loss: 1.4527 - acc: 0.4691 - val_loss: 1.9754 - val_acc: 0.0000e+00\n",
            "Epoch 14/20\n",
            "501/501 [==============================] - 0s 48us/step - loss: 1.3967 - acc: 0.5130 - val_loss: 1.9221 - val_acc: 0.0000e+00\n",
            "Epoch 15/20\n",
            "501/501 [==============================] - 0s 41us/step - loss: 1.3414 - acc: 0.5509 - val_loss: 1.8690 - val_acc: 0.0000e+00\n",
            "Epoch 16/20\n",
            "501/501 [==============================] - 0s 44us/step - loss: 1.2891 - acc: 0.5808 - val_loss: 1.8085 - val_acc: 0.0000e+00\n",
            "Epoch 17/20\n",
            "501/501 [==============================] - 0s 38us/step - loss: 1.2374 - acc: 0.6168 - val_loss: 1.6996 - val_acc: 0.0000e+00\n",
            "Epoch 18/20\n",
            "501/501 [==============================] - 0s 38us/step - loss: 1.1875 - acc: 0.6547 - val_loss: 1.6049 - val_acc: 1.0000\n",
            "Epoch 19/20\n",
            "501/501 [==============================] - 0s 42us/step - loss: 1.1404 - acc: 0.6866 - val_loss: 1.5048 - val_acc: 1.0000\n",
            "Epoch 20/20\n",
            "501/501 [==============================] - 0s 42us/step - loss: 1.0931 - acc: 0.7146 - val_loss: 1.4076 - val_acc: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Architecture</th>\n",
              "      <th>Epoch time</th>\n",
              "      <th>Accuracy Train</th>\n",
              "      <th>Accuracy Test</th>\n",
              "      <th>Loss Train</th>\n",
              "      <th>Loss Test</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>784-256-256-256-256-10</td>\n",
              "      <td>1secs</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0015059779488765996</td>\n",
              "      <td>1.3113030945532955e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>784-128-128-128-128-10</td>\n",
              "      <td>1secs</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.01075358279495539</td>\n",
              "      <td>0.00024673406733199954</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>784-64-64-64-64-10</td>\n",
              "      <td>1secs</td>\n",
              "      <td>0.9940119760479041</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.05011437911012334</td>\n",
              "      <td>2.8729851692332886e-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>784-12-12-12-12-10</td>\n",
              "      <td>1secs</td>\n",
              "      <td>0.3373253504911107</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.7292961498458466</td>\n",
              "      <td>1.5085625648498535</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>784-256-256-256-10</td>\n",
              "      <td>1secs</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0033164129740262996</td>\n",
              "      <td>7.152582838898525e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>784-128-128-128-10</td>\n",
              "      <td>1secs</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.01525082491234153</td>\n",
              "      <td>0.00024065289471764117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>784-64-64-64-10</td>\n",
              "      <td>1secs</td>\n",
              "      <td>0.9900199600798403</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.08408790651314749</td>\n",
              "      <td>0.0006479335715994239</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>784-12-12-12-10</td>\n",
              "      <td>1secs</td>\n",
              "      <td>0.7125748511322006</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.1814940085192165</td>\n",
              "      <td>0.4885764718055725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>784-256-256-10</td>\n",
              "      <td>1secs</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0099775769074862</td>\n",
              "      <td>1.0728893357736524e-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>784-128-128-10</td>\n",
              "      <td>1secs</td>\n",
              "      <td>0.9960079840319361</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.04348168616181243</td>\n",
              "      <td>0.0005690286052413285</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>784-64-64-10</td>\n",
              "      <td>1secs</td>\n",
              "      <td>0.9760479041916168</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.13751532901784855</td>\n",
              "      <td>0.0018042499432340264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>784-12-12-10</td>\n",
              "      <td>1secs</td>\n",
              "      <td>0.7564870264239891</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.9678712405130535</td>\n",
              "      <td>0.10065260529518127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>784-256-10</td>\n",
              "      <td>1secs</td>\n",
              "      <td>0.998003992015968</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.06523270219445466</td>\n",
              "      <td>0.000761381525080651</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>784-128-10</td>\n",
              "      <td>1secs</td>\n",
              "      <td>0.9860279441117764</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.12766101676784827</td>\n",
              "      <td>0.0024485141038894653</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>784-64-10</td>\n",
              "      <td>1secs</td>\n",
              "      <td>0.9720558882235529</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.22942439471176285</td>\n",
              "      <td>0.022408360615372658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>784-12-10</td>\n",
              "      <td>1secs</td>\n",
              "      <td>0.7385229545677018</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0633577134556875</td>\n",
              "      <td>1.407592535018921</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Architecture Epoch time      Accuracy Train Accuracy Test  \\\n",
              "0   784-256-256-256-256-10      1secs                 1.0           1.0   \n",
              "1   784-128-128-128-128-10      1secs                 1.0           1.0   \n",
              "2       784-64-64-64-64-10      1secs  0.9940119760479041           1.0   \n",
              "3       784-12-12-12-12-10      1secs  0.3373253504911107           0.0   \n",
              "4       784-256-256-256-10      1secs                 1.0           1.0   \n",
              "5       784-128-128-128-10      1secs                 1.0           1.0   \n",
              "6          784-64-64-64-10      1secs  0.9900199600798403           1.0   \n",
              "7          784-12-12-12-10      1secs  0.7125748511322006           1.0   \n",
              "8           784-256-256-10      1secs                 1.0           1.0   \n",
              "9           784-128-128-10      1secs  0.9960079840319361           1.0   \n",
              "10            784-64-64-10      1secs  0.9760479041916168           1.0   \n",
              "11            784-12-12-10      1secs  0.7564870264239891           1.0   \n",
              "12              784-256-10      1secs   0.998003992015968           1.0   \n",
              "13              784-128-10      1secs  0.9860279441117764           1.0   \n",
              "14               784-64-10      1secs  0.9720558882235529           1.0   \n",
              "15               784-12-10      1secs  0.7385229545677018           1.0   \n",
              "\n",
              "               Loss Train               Loss Test  \n",
              "0   0.0015059779488765996  1.3113030945532955e-06  \n",
              "1     0.01075358279495539  0.00024673406733199954  \n",
              "2     0.05011437911012334  2.8729851692332886e-05  \n",
              "3      1.7292961498458466      1.5085625648498535  \n",
              "4   0.0033164129740262996   7.152582838898525e-06  \n",
              "5     0.01525082491234153  0.00024065289471764117  \n",
              "6     0.08408790651314749   0.0006479335715994239  \n",
              "7      1.1814940085192165      0.4885764718055725  \n",
              "8      0.0099775769074862  1.0728893357736524e-05  \n",
              "9     0.04348168616181243   0.0005690286052413285  \n",
              "10    0.13751532901784855   0.0018042499432340264  \n",
              "11     0.9678712405130535     0.10065260529518127  \n",
              "12    0.06523270219445466    0.000761381525080651  \n",
              "13    0.12766101676784827   0.0024485141038894653  \n",
              "14    0.22942439471176285    0.022408360615372658  \n",
              "15     1.0633577134556875       1.407592535018921  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXb9yT8tZLRj",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "### Task 3.3 : Odd versus Even Classifier\n",
        "\n",
        "Build a binary classifier that classifiers odd numbers versus even numbers. Again, try to find the best architecture.\n",
        "\n",
        "\n",
        "**Please paste your response here:** \n",
        "* Best archtecture is:  \n",
        "* Test accuracy: \n",
        "* Training time per epoch in seconds is : \n",
        "\n",
        "\n",
        "Please send the following by EMAIL to James.Shanahan@gmail.com with the subject \"Sichuan2019: MNIST Best MLP Architecture\"\n",
        "\n",
        "* Link to Coogle Colab notebook\n",
        "* all the text + your response from this cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-F61Twpw9h7B",
        "colab_type": "code",
        "outputId": "ff98ad46-95a4-4d0b-8dc1-7e38f365590e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 11974
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "results = pd.DataFrame(columns=[\"Architecture\", \"Epoch time\", \"Accuracy Train\", \"Accuracy Test\", \"Loss Train\", \"Loss Test\"])\n",
        "\n",
        "\n",
        "for dense_layer in [4,3,2,1]:\n",
        "  for neuron in [256,128,64,12]:\n",
        "    architecture = '784-'+str(neuron)  \n",
        "    \n",
        "    model_dense = Sequential()  \n",
        "    model_dense.add(Dense(neuron, input_shape=(img_rows * img_cols,), activation=\"relu\"))\n",
        "    \n",
        "    time = 1\n",
        "    while time < dense_layer:#pair other nodes using while loop\n",
        "      architecture+='-'+str(neuron)   \n",
        "      model_dense.add(Dense(neuron, activation=\"relu\"))\n",
        "      time+=1\n",
        "    \n",
        "    \n",
        "    #exchange results in y_train from 1-10 to 1/0\n",
        "    #y_train manifying\n",
        "    even=y_train[1:2] #creat even & odd training data\n",
        "    odd=y_train[3:4]\n",
        "    for i in [ 5,2,13,17]:\n",
        "      even=np.append(even,y_train[i:i+1],axis=0)\n",
        "    for i in [ 7,0,15,4]:\n",
        "      odd=np.append(odd,y_train[i:i+1],axis=0)\n",
        "\n",
        "    y_train_classify=y_train[1:1]\n",
        "    i=0\n",
        "    while i < len(y_train):\n",
        "      if y_train[i:i+1] in even:\n",
        "        y_train_classify=np.append(y_train_classify,y_train[1:2],axis=0)\n",
        "      else:\n",
        "        y_train_classify=np.append(y_train_classify,y_train[3:4],axis=0)\n",
        "      i+=1\n",
        "      \n",
        "      \n",
        "    #y_test manifying   \n",
        "    i=0\n",
        "    y_test_classify=y_test[1:1]\n",
        "    while i < len(y_test):\n",
        "    \n",
        "      if y_test[i:i+1] in even:\n",
        "        y_test_classify=np.append(y_test_classify,y_train[1:2],axis=0)\n",
        "      else:\n",
        "        y_test_classify=np.append(y_test_classify,y_train[3:4],axis=0)\n",
        "      i+=1\n",
        "      \n",
        "      \n",
        "    model_dense.add(Dense(nb_classes, activation=\"softmax\"))\n",
        "    architecture+=\"-2\"\n",
        "      \n",
        "    #compile before training & testing  \n",
        "    model_dense.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    #training & testing (thought this was plotting and deleted, and got 0.01% of accuracy)\n",
        "    hist = model_dense.fit(X_train.reshape((len(X_train), img_cols * img_rows)), y_train_classify, \n",
        "          validation_data = (X_test.reshape((len(X_test), img_cols * img_rows)), y_test_classify), \n",
        "          epochs=20, batch_size=128)\n",
        "\n",
        "    \n",
        "    \n",
        "    score_train = model_dense.evaluate(X_train.reshape((len(X_train), img_cols * img_rows)), y_train_classify, verbose=0)\n",
        "    score_test = model_dense.evaluate(X_test.reshape((len(X_test), img_cols * img_rows)), y_test_classify, verbose=0)\n",
        "\n",
        "\n",
        "      \n",
        "    results.loc[len(results)] = np.array([architecture, \"1secs\", score_train[1], score_test[1], score_train[0], score_test[0]])\n",
        "    #results.index = [\"MLP\"]\n",
        "\n",
        "results\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "60000/60000 [==============================] - 8s 131us/step - loss: 0.0126 - acc: 0.9984 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 7s 122us/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 7s 122us/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 7s 121us/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 7s 119us/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 7s 120us/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 7s 121us/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 7s 120us/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 7s 120us/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 7s 121us/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 7s 120us/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 7s 121us/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 7s 121us/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 8s 127us/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 8s 126us/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 7s 122us/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 7s 121us/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 8s 127us/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 7s 122us/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.0211 - acc: 0.9968 - val_loss: 1.1947e-07 - val_acc: 1.0000\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 5s 78us/step - loss: 1.2015e-07 - acc: 1.0000 - val_loss: 1.1947e-07 - val_acc: 1.0000\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 4s 70us/step - loss: 1.2015e-07 - acc: 1.0000 - val_loss: 1.1947e-07 - val_acc: 1.0000\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 4s 68us/step - loss: 1.2015e-07 - acc: 1.0000 - val_loss: 1.1947e-07 - val_acc: 1.0000\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 1.2015e-07 - acc: 1.0000 - val_loss: 1.1947e-07 - val_acc: 1.0000\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 1.2015e-07 - acc: 1.0000 - val_loss: 1.1947e-07 - val_acc: 1.0000\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 4s 68us/step - loss: 1.2015e-07 - acc: 1.0000 - val_loss: 1.1947e-07 - val_acc: 1.0000\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 1.2015e-07 - acc: 1.0000 - val_loss: 1.1947e-07 - val_acc: 1.0000\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 4s 68us/step - loss: 1.2014e-07 - acc: 1.0000 - val_loss: 1.1947e-07 - val_acc: 1.0000\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 1.2014e-07 - acc: 1.0000 - val_loss: 1.1946e-07 - val_acc: 1.0000\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 4s 68us/step - loss: 1.2014e-07 - acc: 1.0000 - val_loss: 1.1946e-07 - val_acc: 1.0000\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 4s 68us/step - loss: 1.2013e-07 - acc: 1.0000 - val_loss: 1.1946e-07 - val_acc: 1.0000\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 1.2012e-07 - acc: 1.0000 - val_loss: 1.1946e-07 - val_acc: 1.0000\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 4s 70us/step - loss: 1.2012e-07 - acc: 1.0000 - val_loss: 1.1946e-07 - val_acc: 1.0000\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 4s 68us/step - loss: 1.2010e-07 - acc: 1.0000 - val_loss: 1.1946e-07 - val_acc: 1.0000\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 4s 68us/step - loss: 1.2009e-07 - acc: 1.0000 - val_loss: 1.1946e-07 - val_acc: 1.0000\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 1.2007e-07 - acc: 1.0000 - val_loss: 1.1945e-07 - val_acc: 1.0000\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 1.2004e-07 - acc: 1.0000 - val_loss: 1.1945e-07 - val_acc: 1.0000\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 1.2002e-07 - acc: 1.0000 - val_loss: 1.1944e-07 - val_acc: 1.0000\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 1.1999e-07 - acc: 1.0000 - val_loss: 1.1942e-07 - val_acc: 1.0000\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.0413 - acc: 0.9962 - val_loss: 3.7871e-06 - val_acc: 1.0000\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 1.7620e-06 - acc: 1.0000 - val_loss: 8.4366e-07 - val_acc: 1.0000\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 5.8515e-07 - acc: 1.0000 - val_loss: 4.1112e-07 - val_acc: 1.0000\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 3s 43us/step - loss: 3.3480e-07 - acc: 1.0000 - val_loss: 2.7452e-07 - val_acc: 1.0000\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 2.3993e-07 - acc: 1.0000 - val_loss: 2.1254e-07 - val_acc: 1.0000\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 1.9379e-07 - acc: 1.0000 - val_loss: 1.7974e-07 - val_acc: 1.0000\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 1.6811e-07 - acc: 1.0000 - val_loss: 1.6081e-07 - val_acc: 1.0000\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 1.5258e-07 - acc: 1.0000 - val_loss: 1.4879e-07 - val_acc: 1.0000\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 1.4270e-07 - acc: 1.0000 - val_loss: 1.4061e-07 - val_acc: 1.0000\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 1.3613e-07 - acc: 1.0000 - val_loss: 1.3513e-07 - val_acc: 1.0000\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 2s 40us/step - loss: 1.3156e-07 - acc: 1.0000 - val_loss: 1.3126e-07 - val_acc: 1.0000\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 1.2834e-07 - acc: 1.0000 - val_loss: 1.2837e-07 - val_acc: 1.0000\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 1.2608e-07 - acc: 1.0000 - val_loss: 1.2640e-07 - val_acc: 1.0000\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 1.2441e-07 - acc: 1.0000 - val_loss: 1.2486e-07 - val_acc: 1.0000\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 1.2321e-07 - acc: 1.0000 - val_loss: 1.2367e-07 - val_acc: 1.0000\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 1.2228e-07 - acc: 1.0000 - val_loss: 1.2277e-07 - val_acc: 1.0000\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 1.2159e-07 - acc: 1.0000 - val_loss: 1.2206e-07 - val_acc: 1.0000\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 1.2106e-07 - acc: 1.0000 - val_loss: 1.2159e-07 - val_acc: 1.0000\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 2s 40us/step - loss: 1.2068e-07 - acc: 1.0000 - val_loss: 1.2118e-07 - val_acc: 1.0000\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 1.2039e-07 - acc: 1.0000 - val_loss: 1.2082e-07 - val_acc: 1.0000\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "60000/60000 [==============================] - 2s 36us/step - loss: 0.1942 - acc: 0.9189 - val_loss: 6.2871e-04 - val_acc: 1.0000\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 1s 23us/step - loss: 3.3612e-04 - acc: 1.0000 - val_loss: 1.7254e-04 - val_acc: 1.0000\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 1s 23us/step - loss: 1.1680e-04 - acc: 1.0000 - val_loss: 7.6804e-05 - val_acc: 1.0000\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 1s 23us/step - loss: 5.6568e-05 - acc: 1.0000 - val_loss: 4.0347e-05 - val_acc: 1.0000\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 1s 23us/step - loss: 2.8886e-05 - acc: 1.0000 - val_loss: 1.9483e-05 - val_acc: 1.0000\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 1s 23us/step - loss: 1.3004e-05 - acc: 1.0000 - val_loss: 8.4843e-06 - val_acc: 1.0000\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 1s 23us/step - loss: 5.7503e-06 - acc: 1.0000 - val_loss: 4.0519e-06 - val_acc: 1.0000\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 2.8880e-06 - acc: 1.0000 - val_loss: 2.2325e-06 - val_acc: 1.0000\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 1.6450e-06 - acc: 1.0000 - val_loss: 1.3619e-06 - val_acc: 1.0000\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 1.0340e-06 - acc: 1.0000 - val_loss: 9.0223e-07 - val_acc: 1.0000\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 7.0366e-07 - acc: 1.0000 - val_loss: 6.4172e-07 - val_acc: 1.0000\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 5.1024e-07 - acc: 1.0000 - val_loss: 4.7962e-07 - val_acc: 1.0000\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 3.8818e-07 - acc: 1.0000 - val_loss: 3.7336e-07 - val_acc: 1.0000\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 3.0826e-07 - acc: 1.0000 - val_loss: 3.0231e-07 - val_acc: 1.0000\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 2.5453e-07 - acc: 1.0000 - val_loss: 2.5327e-07 - val_acc: 1.0000\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 2.1745e-07 - acc: 1.0000 - val_loss: 2.1820e-07 - val_acc: 1.0000\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 1.9123e-07 - acc: 1.0000 - val_loss: 1.9303e-07 - val_acc: 1.0000\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 1.7243e-07 - acc: 1.0000 - val_loss: 1.7480e-07 - val_acc: 1.0000\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 1.5891e-07 - acc: 1.0000 - val_loss: 1.6165e-07 - val_acc: 1.0000\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 1.4915e-07 - acc: 1.0000 - val_loss: 1.5178e-07 - val_acc: 1.0000\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "60000/60000 [==============================] - 8s 137us/step - loss: 0.0111 - acc: 0.9983 - val_loss: 1.1928e-07 - val_acc: 1.0000\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 7s 112us/step - loss: 1.1929e-07 - acc: 1.0000 - val_loss: 1.1928e-07 - val_acc: 1.0000\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 6s 101us/step - loss: 1.1929e-07 - acc: 1.0000 - val_loss: 1.1928e-07 - val_acc: 1.0000\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 6s 101us/step - loss: 1.1929e-07 - acc: 1.0000 - val_loss: 1.1928e-07 - val_acc: 1.0000\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 1.1929e-07 - acc: 1.0000 - val_loss: 1.1928e-07 - val_acc: 1.0000\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 1.1929e-07 - acc: 1.0000 - val_loss: 1.1928e-07 - val_acc: 1.0000\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 6s 104us/step - loss: 1.1929e-07 - acc: 1.0000 - val_loss: 1.1928e-07 - val_acc: 1.0000\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 6s 106us/step - loss: 1.1929e-07 - acc: 1.0000 - val_loss: 1.1928e-07 - val_acc: 1.0000\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 6s 104us/step - loss: 1.1929e-07 - acc: 1.0000 - val_loss: 1.1928e-07 - val_acc: 1.0000\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 1.1929e-07 - acc: 1.0000 - val_loss: 1.1928e-07 - val_acc: 1.0000\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 1.1929e-07 - acc: 1.0000 - val_loss: 1.1928e-07 - val_acc: 1.0000\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 1.1929e-07 - acc: 1.0000 - val_loss: 1.1928e-07 - val_acc: 1.0000\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 7s 113us/step - loss: 1.1929e-07 - acc: 1.0000 - val_loss: 1.1928e-07 - val_acc: 1.0000\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 1.1929e-07 - acc: 1.0000 - val_loss: 1.1928e-07 - val_acc: 1.0000\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 1.1929e-07 - acc: 1.0000 - val_loss: 1.1928e-07 - val_acc: 1.0000\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 6s 100us/step - loss: 1.1929e-07 - acc: 1.0000 - val_loss: 1.1928e-07 - val_acc: 1.0000\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 6s 104us/step - loss: 1.1929e-07 - acc: 1.0000 - val_loss: 1.1928e-07 - val_acc: 1.0000\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 1.1929e-07 - acc: 1.0000 - val_loss: 1.1928e-07 - val_acc: 1.0000\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 6s 107us/step - loss: 1.1929e-07 - acc: 1.0000 - val_loss: 1.1928e-07 - val_acc: 1.0000\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 1.1928e-07 - acc: 1.0000 - val_loss: 1.1928e-07 - val_acc: 1.0000\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "60000/60000 [==============================] - 4s 73us/step - loss: 0.0193 - acc: 0.9966 - val_loss: 9.0220e-07 - val_acc: 1.0000\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 4s 62us/step - loss: 8.6897e-07 - acc: 1.0000 - val_loss: 7.6842e-07 - val_acc: 1.0000\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 4s 62us/step - loss: 7.1851e-07 - acc: 1.0000 - val_loss: 6.1491e-07 - val_acc: 1.0000\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 4s 62us/step - loss: 5.6699e-07 - acc: 1.0000 - val_loss: 4.7570e-07 - val_acc: 1.0000\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 4s 61us/step - loss: 4.3564e-07 - acc: 1.0000 - val_loss: 3.6141e-07 - val_acc: 1.0000\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 4s 61us/step - loss: 3.3148e-07 - acc: 1.0000 - val_loss: 2.7634e-07 - val_acc: 1.0000\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 4s 61us/step - loss: 2.5773e-07 - acc: 1.0000 - val_loss: 2.1972e-07 - val_acc: 1.0000\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 2.1013e-07 - acc: 1.0000 - val_loss: 1.8500e-07 - val_acc: 1.0000\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 1.7970e-07 - acc: 1.0000 - val_loss: 1.6272e-07 - val_acc: 1.0000\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 1.6037e-07 - acc: 1.0000 - val_loss: 1.4871e-07 - val_acc: 1.0000\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 1.4774e-07 - acc: 1.0000 - val_loss: 1.3960e-07 - val_acc: 1.0000\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 1.3931e-07 - acc: 1.0000 - val_loss: 1.3369e-07 - val_acc: 1.0000\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 1.3366e-07 - acc: 1.0000 - val_loss: 1.2964e-07 - val_acc: 1.0000\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 1.2972e-07 - acc: 1.0000 - val_loss: 1.2676e-07 - val_acc: 1.0000\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 4s 58us/step - loss: 1.2696e-07 - acc: 1.0000 - val_loss: 1.2478e-07 - val_acc: 1.0000\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 1.2502e-07 - acc: 1.0000 - val_loss: 1.2341e-07 - val_acc: 1.0000\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 1.2359e-07 - acc: 1.0000 - val_loss: 1.2231e-07 - val_acc: 1.0000\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 1.2256e-07 - acc: 1.0000 - val_loss: 1.2162e-07 - val_acc: 1.0000\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 1.2177e-07 - acc: 1.0000 - val_loss: 1.2106e-07 - val_acc: 1.0000\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 1.2121e-07 - acc: 1.0000 - val_loss: 1.2062e-07 - val_acc: 1.0000\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0204 - acc: 0.9991 - val_loss: 7.1594e-06 - val_acc: 1.0000\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 2.4295e-06 - acc: 1.0000 - val_loss: 1.4548e-06 - val_acc: 1.0000\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 2s 36us/step - loss: 6.8463e-07 - acc: 1.0000 - val_loss: 6.7831e-07 - val_acc: 1.0000\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 2s 36us/step - loss: 3.6318e-07 - acc: 1.0000 - val_loss: 4.2689e-07 - val_acc: 1.0000\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 2s 35us/step - loss: 2.4953e-07 - acc: 1.0000 - val_loss: 3.0874e-07 - val_acc: 1.0000\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 2s 36us/step - loss: 1.9625e-07 - acc: 1.0000 - val_loss: 2.4332e-07 - val_acc: 1.0000\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 2s 40us/step - loss: 1.6788e-07 - acc: 1.0000 - val_loss: 2.0471e-07 - val_acc: 1.0000\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 2s 40us/step - loss: 1.5120e-07 - acc: 1.0000 - val_loss: 1.8012e-07 - val_acc: 1.0000\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 1.4096e-07 - acc: 1.0000 - val_loss: 1.6390e-07 - val_acc: 1.0000\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 1.3457e-07 - acc: 1.0000 - val_loss: 1.5299e-07 - val_acc: 1.0000\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 1.3017e-07 - acc: 1.0000 - val_loss: 1.4500e-07 - val_acc: 1.0000\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 3s 45us/step - loss: 1.2720e-07 - acc: 1.0000 - val_loss: 1.3931e-07 - val_acc: 1.0000\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 1.2511e-07 - acc: 1.0000 - val_loss: 1.3511e-07 - val_acc: 1.0000\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 2s 40us/step - loss: 1.2366e-07 - acc: 1.0000 - val_loss: 1.3194e-07 - val_acc: 1.0000\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 2s 40us/step - loss: 1.2258e-07 - acc: 1.0000 - val_loss: 1.2954e-07 - val_acc: 1.0000\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 1.2177e-07 - acc: 1.0000 - val_loss: 1.2760e-07 - val_acc: 1.0000\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 1.2119e-07 - acc: 1.0000 - val_loss: 1.2620e-07 - val_acc: 1.0000\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 1.2075e-07 - acc: 1.0000 - val_loss: 1.2500e-07 - val_acc: 1.0000\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 1.2044e-07 - acc: 1.0000 - val_loss: 1.2411e-07 - val_acc: 1.0000\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 1.2017e-07 - acc: 1.0000 - val_loss: 1.2334e-07 - val_acc: 1.0000\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "60000/60000 [==============================] - 3s 43us/step - loss: 0.2204 - acc: 0.9274 - val_loss: 0.0013 - val_acc: 1.0000\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 6.9238e-04 - acc: 1.0000 - val_loss: 3.4714e-04 - val_acc: 1.0000\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 2.3066e-04 - acc: 1.0000 - val_loss: 1.5406e-04 - val_acc: 1.0000\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 1.1204e-04 - acc: 1.0000 - val_loss: 8.4533e-05 - val_acc: 1.0000\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 6.4062e-05 - acc: 1.0000 - val_loss: 5.1726e-05 - val_acc: 1.0000\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 4.0145e-05 - acc: 1.0000 - val_loss: 3.3880e-05 - val_acc: 1.0000\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6619e-05 - acc: 1.0000 - val_loss: 2.3256e-05 - val_acc: 1.0000\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 1.8336e-05 - acc: 1.0000 - val_loss: 1.6423e-05 - val_acc: 1.0000\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 1.2969e-05 - acc: 1.0000 - val_loss: 1.1901e-05 - val_acc: 1.0000\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 9.3529e-06 - acc: 1.0000 - val_loss: 8.7733e-06 - val_acc: 1.0000\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 6.8571e-06 - acc: 1.0000 - val_loss: 6.5255e-06 - val_acc: 1.0000\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 5.0939e-06 - acc: 1.0000 - val_loss: 4.9340e-06 - val_acc: 1.0000\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 3.8159e-06 - acc: 1.0000 - val_loss: 3.7658e-06 - val_acc: 1.0000\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 2.8823e-06 - acc: 1.0000 - val_loss: 2.8883e-06 - val_acc: 1.0000\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 2.1961e-06 - acc: 1.0000 - val_loss: 2.2349e-06 - val_acc: 1.0000\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 1.6872e-06 - acc: 1.0000 - val_loss: 1.7478e-06 - val_acc: 1.0000\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 1.3054e-06 - acc: 1.0000 - val_loss: 1.3757e-06 - val_acc: 1.0000\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 1.0185e-06 - acc: 1.0000 - val_loss: 1.0887e-06 - val_acc: 1.0000\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 8.0296e-07 - acc: 1.0000 - val_loss: 8.7126e-07 - val_acc: 1.0000\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 6.3975e-07 - acc: 1.0000 - val_loss: 7.0290e-07 - val_acc: 1.0000\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 0.0108 - acc: 0.9982 - val_loss: 4.2811e-07 - val_acc: 1.0000\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 6s 98us/step - loss: 3.9851e-07 - acc: 1.0000 - val_loss: 4.0881e-07 - val_acc: 1.0000\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 3.7699e-07 - acc: 1.0000 - val_loss: 3.8350e-07 - val_acc: 1.0000\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 6s 94us/step - loss: 3.3764e-07 - acc: 1.0000 - val_loss: 2.9048e-07 - val_acc: 1.0000\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 6s 93us/step - loss: 2.0417e-07 - acc: 1.0000 - val_loss: 1.6232e-07 - val_acc: 1.0000\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 5s 90us/step - loss: 1.4391e-07 - acc: 1.0000 - val_loss: 1.3643e-07 - val_acc: 1.0000\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 5s 87us/step - loss: 1.3064e-07 - acc: 1.0000 - val_loss: 1.2897e-07 - val_acc: 1.0000\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 6s 96us/step - loss: 1.2588e-07 - acc: 1.0000 - val_loss: 1.2524e-07 - val_acc: 1.0000\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 6s 98us/step - loss: 1.2360e-07 - acc: 1.0000 - val_loss: 1.2339e-07 - val_acc: 1.0000\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 6s 97us/step - loss: 1.2229e-07 - acc: 1.0000 - val_loss: 1.2228e-07 - val_acc: 1.0000\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 6s 98us/step - loss: 1.2151e-07 - acc: 1.0000 - val_loss: 1.2158e-07 - val_acc: 1.0000\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 6s 98us/step - loss: 1.2098e-07 - acc: 1.0000 - val_loss: 1.2107e-07 - val_acc: 1.0000\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 1.2061e-07 - acc: 1.0000 - val_loss: 1.2075e-07 - val_acc: 1.0000\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 5s 90us/step - loss: 1.2036e-07 - acc: 1.0000 - val_loss: 1.2047e-07 - val_acc: 1.0000\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 5s 91us/step - loss: 1.2016e-07 - acc: 1.0000 - val_loss: 1.2028e-07 - val_acc: 1.0000\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 5s 86us/step - loss: 1.2001e-07 - acc: 1.0000 - val_loss: 1.2013e-07 - val_acc: 1.0000\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 1.1988e-07 - acc: 1.0000 - val_loss: 1.1998e-07 - val_acc: 1.0000\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 6s 93us/step - loss: 1.1979e-07 - acc: 1.0000 - val_loss: 1.1989e-07 - val_acc: 1.0000\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 6s 93us/step - loss: 1.1971e-07 - acc: 1.0000 - val_loss: 1.1981e-07 - val_acc: 1.0000\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 6s 97us/step - loss: 1.1966e-07 - acc: 1.0000 - val_loss: 1.1976e-07 - val_acc: 1.0000\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "60000/60000 [==============================] - 5s 77us/step - loss: 0.0243 - acc: 0.9954 - val_loss: 1.4707e-05 - val_acc: 1.0000\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 3s 52us/step - loss: 7.4123e-06 - acc: 1.0000 - val_loss: 3.7184e-06 - val_acc: 1.0000\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 3s 50us/step - loss: 2.0927e-06 - acc: 1.0000 - val_loss: 1.3957e-06 - val_acc: 1.0000\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 3s 51us/step - loss: 9.0569e-07 - acc: 1.0000 - val_loss: 7.4054e-07 - val_acc: 1.0000\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 3s 50us/step - loss: 5.2204e-07 - acc: 1.0000 - val_loss: 4.7465e-07 - val_acc: 1.0000\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 3.5394e-07 - acc: 1.0000 - val_loss: 3.4022e-07 - val_acc: 1.0000\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 2.6707e-07 - acc: 1.0000 - val_loss: 2.6700e-07 - val_acc: 1.0000\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 2.1796e-07 - acc: 1.0000 - val_loss: 2.2200e-07 - val_acc: 1.0000\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 3s 51us/step - loss: 1.8737e-07 - acc: 1.0000 - val_loss: 1.9282e-07 - val_acc: 1.0000\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 1.6743e-07 - acc: 1.0000 - val_loss: 1.7316e-07 - val_acc: 1.0000\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 3s 51us/step - loss: 1.5394e-07 - acc: 1.0000 - val_loss: 1.5920e-07 - val_acc: 1.0000\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 3s 50us/step - loss: 1.4453e-07 - acc: 1.0000 - val_loss: 1.4928e-07 - val_acc: 1.0000\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 4s 64us/step - loss: 1.3803e-07 - acc: 1.0000 - val_loss: 1.4205e-07 - val_acc: 1.0000\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 1.3330e-07 - acc: 1.0000 - val_loss: 1.3686e-07 - val_acc: 1.0000\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 1.2985e-07 - acc: 1.0000 - val_loss: 1.3297e-07 - val_acc: 1.0000\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 1.2733e-07 - acc: 1.0000 - val_loss: 1.3004e-07 - val_acc: 1.0000\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 3s 51us/step - loss: 1.2541e-07 - acc: 1.0000 - val_loss: 1.2777e-07 - val_acc: 1.0000\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 3s 51us/step - loss: 1.2398e-07 - acc: 1.0000 - val_loss: 1.2605e-07 - val_acc: 1.0000\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 3s 51us/step - loss: 1.2295e-07 - acc: 1.0000 - val_loss: 1.2477e-07 - val_acc: 1.0000\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 3s 51us/step - loss: 1.2213e-07 - acc: 1.0000 - val_loss: 1.2375e-07 - val_acc: 1.0000\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 0.0322 - acc: 0.9957 - val_loss: 1.1105e-05 - val_acc: 1.0000\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 2.2877e-06 - acc: 1.0000 - val_loss: 1.0453e-06 - val_acc: 1.0000\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 4.9070e-07 - acc: 1.0000 - val_loss: 5.0768e-07 - val_acc: 1.0000\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 2s 34us/step - loss: 2.8034e-07 - acc: 1.0000 - val_loss: 3.4017e-07 - val_acc: 1.0000\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 2.0717e-07 - acc: 1.0000 - val_loss: 2.6339e-07 - val_acc: 1.0000\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 1.7322e-07 - acc: 1.0000 - val_loss: 2.1917e-07 - val_acc: 1.0000\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 2s 34us/step - loss: 1.5477e-07 - acc: 1.0000 - val_loss: 1.9225e-07 - val_acc: 1.0000\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 1.4382e-07 - acc: 1.0000 - val_loss: 1.7426e-07 - val_acc: 1.0000\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 1.3674e-07 - acc: 1.0000 - val_loss: 1.6206e-07 - val_acc: 1.0000\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 1.3192e-07 - acc: 1.0000 - val_loss: 1.5241e-07 - val_acc: 1.0000\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 1.2860e-07 - acc: 1.0000 - val_loss: 1.4595e-07 - val_acc: 1.0000\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 1.2627e-07 - acc: 1.0000 - val_loss: 1.4026e-07 - val_acc: 1.0000\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 1.2456e-07 - acc: 1.0000 - val_loss: 1.3614e-07 - val_acc: 1.0000\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 1.2331e-07 - acc: 1.0000 - val_loss: 1.3309e-07 - val_acc: 1.0000\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 1.2240e-07 - acc: 1.0000 - val_loss: 1.3049e-07 - val_acc: 1.0000\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 1.2169e-07 - acc: 1.0000 - val_loss: 1.2854e-07 - val_acc: 1.0000\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 1.2115e-07 - acc: 1.0000 - val_loss: 1.2689e-07 - val_acc: 1.0000\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 1.2076e-07 - acc: 1.0000 - val_loss: 1.2563e-07 - val_acc: 1.0000\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 1.2046e-07 - acc: 1.0000 - val_loss: 1.2462e-07 - val_acc: 1.0000\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 1.2021e-07 - acc: 1.0000 - val_loss: 1.2379e-07 - val_acc: 1.0000\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "60000/60000 [==============================] - 3s 44us/step - loss: 0.0823 - acc: 0.9940 - val_loss: 9.4241e-04 - val_acc: 1.0000\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 1s 23us/step - loss: 4.8754e-04 - acc: 1.0000 - val_loss: 2.3810e-04 - val_acc: 1.0000\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 1.5525e-04 - acc: 1.0000 - val_loss: 1.0014e-04 - val_acc: 1.0000\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 1s 23us/step - loss: 7.1641e-05 - acc: 1.0000 - val_loss: 5.2316e-05 - val_acc: 1.0000\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 1s 23us/step - loss: 3.9060e-05 - acc: 1.0000 - val_loss: 3.0576e-05 - val_acc: 1.0000\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 2.3344e-05 - acc: 1.0000 - val_loss: 1.9175e-05 - val_acc: 1.0000\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 1.4866e-05 - acc: 1.0000 - val_loss: 1.2689e-05 - val_acc: 1.0000\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 1s 23us/step - loss: 9.8943e-06 - acc: 1.0000 - val_loss: 8.6879e-06 - val_acc: 1.0000\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 6.7924e-06 - acc: 1.0000 - val_loss: 6.1109e-06 - val_acc: 1.0000\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 4.7720e-06 - acc: 1.0000 - val_loss: 4.3824e-06 - val_acc: 1.0000\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 3.4185e-06 - acc: 1.0000 - val_loss: 3.2011e-06 - val_acc: 1.0000\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 2.4957e-06 - acc: 1.0000 - val_loss: 2.3875e-06 - val_acc: 1.0000\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 1s 23us/step - loss: 1.8495e-06 - acc: 1.0000 - val_loss: 1.7976e-06 - val_acc: 1.0000\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 1s 23us/step - loss: 1.3909e-06 - acc: 1.0000 - val_loss: 1.3745e-06 - val_acc: 1.0000\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 1s 23us/step - loss: 1.0590e-06 - acc: 1.0000 - val_loss: 1.0660e-06 - val_acc: 1.0000\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 1s 23us/step - loss: 8.1657e-07 - acc: 1.0000 - val_loss: 8.2921e-07 - val_acc: 1.0000\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 6.4077e-07 - acc: 1.0000 - val_loss: 6.6166e-07 - val_acc: 1.0000\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 1s 23us/step - loss: 5.1016e-07 - acc: 1.0000 - val_loss: 5.3044e-07 - val_acc: 1.0000\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 4.1245e-07 - acc: 1.0000 - val_loss: 4.3381e-07 - val_acc: 1.0000\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 1s 23us/step - loss: 3.3991e-07 - acc: 1.0000 - val_loss: 3.6104e-07 - val_acc: 1.0000\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "60000/60000 [==============================] - 6s 102us/step - loss: 0.0188 - acc: 0.9956 - val_loss: 4.0859e-05 - val_acc: 1.0000\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 5s 77us/step - loss: 1.8598e-05 - acc: 1.0000 - val_loss: 9.6812e-06 - val_acc: 1.0000\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 5s 77us/step - loss: 5.5753e-06 - acc: 1.0000 - val_loss: 4.1674e-06 - val_acc: 1.0000\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 5s 78us/step - loss: 2.5819e-06 - acc: 1.0000 - val_loss: 2.2812e-06 - val_acc: 1.0000\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 5s 81us/step - loss: 1.4659e-06 - acc: 1.0000 - val_loss: 1.4425e-06 - val_acc: 1.0000\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 5s 82us/step - loss: 9.4352e-07 - acc: 1.0000 - val_loss: 9.9761e-07 - val_acc: 1.0000\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 5s 83us/step - loss: 6.5789e-07 - acc: 1.0000 - val_loss: 7.2841e-07 - val_acc: 1.0000\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 5s 82us/step - loss: 4.8600e-07 - acc: 1.0000 - val_loss: 5.5805e-07 - val_acc: 1.0000\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 5s 81us/step - loss: 3.7631e-07 - acc: 1.0000 - val_loss: 4.4381e-07 - val_acc: 1.0000\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 5s 80us/step - loss: 3.0326e-07 - acc: 1.0000 - val_loss: 3.6071e-07 - val_acc: 1.0000\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 5s 82us/step - loss: 2.5318e-07 - acc: 1.0000 - val_loss: 3.0266e-07 - val_acc: 1.0000\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 5s 80us/step - loss: 2.1818e-07 - acc: 1.0000 - val_loss: 2.6135e-07 - val_acc: 1.0000\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 5s 77us/step - loss: 1.9313e-07 - acc: 1.0000 - val_loss: 2.2886e-07 - val_acc: 1.0000\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 5s 77us/step - loss: 1.7486e-07 - acc: 1.0000 - val_loss: 2.0554e-07 - val_acc: 1.0000\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 5s 77us/step - loss: 1.6148e-07 - acc: 1.0000 - val_loss: 1.8750e-07 - val_acc: 1.0000\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 1.5162e-07 - acc: 1.0000 - val_loss: 1.7353e-07 - val_acc: 1.0000\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 1.4412e-07 - acc: 1.0000 - val_loss: 1.6261e-07 - val_acc: 1.0000\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 1.3849e-07 - acc: 1.0000 - val_loss: 1.5400e-07 - val_acc: 1.0000\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 5s 77us/step - loss: 1.3422e-07 - acc: 1.0000 - val_loss: 1.4760e-07 - val_acc: 1.0000\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 5s 78us/step - loss: 1.3097e-07 - acc: 1.0000 - val_loss: 1.4221e-07 - val_acc: 1.0000\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "60000/60000 [==============================] - 5s 82us/step - loss: 0.0148 - acc: 0.9979 - val_loss: 3.6851e-05 - val_acc: 1.0000\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 1.7000e-05 - acc: 1.0000 - val_loss: 8.5477e-06 - val_acc: 1.0000\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 3s 50us/step - loss: 5.1816e-06 - acc: 1.0000 - val_loss: 3.7489e-06 - val_acc: 1.0000\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 3s 49us/step - loss: 2.4765e-06 - acc: 1.0000 - val_loss: 2.0857e-06 - val_acc: 1.0000\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 3s 49us/step - loss: 1.4295e-06 - acc: 1.0000 - val_loss: 1.3182e-06 - val_acc: 1.0000\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 9.2361e-07 - acc: 1.0000 - val_loss: 9.0895e-07 - val_acc: 1.0000\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 3s 49us/step - loss: 6.4674e-07 - acc: 1.0000 - val_loss: 6.6457e-07 - val_acc: 1.0000\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 3s 48us/step - loss: 4.8053e-07 - acc: 1.0000 - val_loss: 5.1069e-07 - val_acc: 1.0000\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 3s 51us/step - loss: 3.7454e-07 - acc: 1.0000 - val_loss: 4.0897e-07 - val_acc: 1.0000\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 3s 49us/step - loss: 3.0285e-07 - acc: 1.0000 - val_loss: 3.3477e-07 - val_acc: 1.0000\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 3s 48us/step - loss: 2.5333e-07 - acc: 1.0000 - val_loss: 2.8237e-07 - val_acc: 1.0000\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 2.1862e-07 - acc: 1.0000 - val_loss: 2.4435e-07 - val_acc: 1.0000\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 3s 48us/step - loss: 1.9342e-07 - acc: 1.0000 - val_loss: 2.1599e-07 - val_acc: 1.0000\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 1.7519e-07 - acc: 1.0000 - val_loss: 1.9464e-07 - val_acc: 1.0000\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 1.6170e-07 - acc: 1.0000 - val_loss: 1.7849e-07 - val_acc: 1.0000\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 3s 48us/step - loss: 1.5163e-07 - acc: 1.0000 - val_loss: 1.6592e-07 - val_acc: 1.0000\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 1.4414e-07 - acc: 1.0000 - val_loss: 1.5649e-07 - val_acc: 1.0000\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 3s 48us/step - loss: 1.3840e-07 - acc: 1.0000 - val_loss: 1.4888e-07 - val_acc: 1.0000\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 1.3407e-07 - acc: 1.0000 - val_loss: 1.4299e-07 - val_acc: 1.0000\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 3s 48us/step - loss: 1.3080e-07 - acc: 1.0000 - val_loss: 1.3840e-07 - val_acc: 1.0000\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.0315 - acc: 0.9946 - val_loss: 4.1823e-04 - val_acc: 1.0000\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 2.3255e-04 - acc: 1.0000 - val_loss: 1.2957e-04 - val_acc: 1.0000\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 2s 35us/step - loss: 8.7547e-05 - acc: 1.0000 - val_loss: 6.1801e-05 - val_acc: 1.0000\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 4.4723e-05 - acc: 1.0000 - val_loss: 3.5361e-05 - val_acc: 1.0000\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 2s 35us/step - loss: 2.6342e-05 - acc: 1.0000 - val_loss: 2.2245e-05 - val_acc: 1.0000\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 1.6840e-05 - acc: 1.0000 - val_loss: 1.5037e-05 - val_acc: 1.0000\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 1.1362e-05 - acc: 1.0000 - val_loss: 1.0562e-05 - val_acc: 1.0000\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 7.9522e-06 - acc: 1.0000 - val_loss: 7.6573e-06 - val_acc: 1.0000\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 5.7046e-06 - acc: 1.0000 - val_loss: 5.6955e-06 - val_acc: 1.0000\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 2s 34us/step - loss: 4.1783e-06 - acc: 1.0000 - val_loss: 4.3160e-06 - val_acc: 1.0000\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 3.1045e-06 - acc: 1.0000 - val_loss: 3.2898e-06 - val_acc: 1.0000\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 2.3374e-06 - acc: 1.0000 - val_loss: 2.5469e-06 - val_acc: 1.0000\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 1.7803e-06 - acc: 1.0000 - val_loss: 1.9973e-06 - val_acc: 1.0000\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 1.3705e-06 - acc: 1.0000 - val_loss: 1.5739e-06 - val_acc: 1.0000\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 2s 34us/step - loss: 1.0653e-06 - acc: 1.0000 - val_loss: 1.2558e-06 - val_acc: 1.0000\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 8.3732e-07 - acc: 1.0000 - val_loss: 1.0115e-06 - val_acc: 1.0000\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 6.6625e-07 - acc: 1.0000 - val_loss: 8.2268e-07 - val_acc: 1.0000\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 2s 35us/step - loss: 5.3786e-07 - acc: 1.0000 - val_loss: 6.7741e-07 - val_acc: 1.0000\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 4.3977e-07 - acc: 1.0000 - val_loss: 5.6298e-07 - val_acc: 1.0000\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 3.6502e-07 - acc: 1.0000 - val_loss: 4.7242e-07 - val_acc: 1.0000\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "60000/60000 [==============================] - 3s 48us/step - loss: 0.0547 - acc: 0.9953 - val_loss: 0.0016 - val_acc: 1.0000\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 1s 23us/step - loss: 9.4187e-04 - acc: 1.0000 - val_loss: 5.2167e-04 - val_acc: 1.0000\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 3.7084e-04 - acc: 1.0000 - val_loss: 2.5916e-04 - val_acc: 1.0000\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 1.9767e-04 - acc: 1.0000 - val_loss: 1.5266e-04 - val_acc: 1.0000\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 1s 23us/step - loss: 1.2062e-04 - acc: 1.0000 - val_loss: 9.9087e-05 - val_acc: 1.0000\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 7.9410e-05 - acc: 1.0000 - val_loss: 6.8112e-05 - val_acc: 1.0000\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 5.4810e-05 - acc: 1.0000 - val_loss: 4.8586e-05 - val_acc: 1.0000\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 1s 23us/step - loss: 3.9064e-05 - acc: 1.0000 - val_loss: 3.5572e-05 - val_acc: 1.0000\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 1s 23us/step - loss: 2.8521e-05 - acc: 1.0000 - val_loss: 2.6621e-05 - val_acc: 1.0000\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 1s 23us/step - loss: 2.1198e-05 - acc: 1.0000 - val_loss: 2.0266e-05 - val_acc: 1.0000\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 1s 23us/step - loss: 1.5940e-05 - acc: 1.0000 - val_loss: 1.5558e-05 - val_acc: 1.0000\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 1.2102e-05 - acc: 1.0000 - val_loss: 1.2038e-05 - val_acc: 1.0000\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 1s 23us/step - loss: 9.2520e-06 - acc: 1.0000 - val_loss: 9.3887e-06 - val_acc: 1.0000\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 1s 23us/step - loss: 7.1223e-06 - acc: 1.0000 - val_loss: 7.3996e-06 - val_acc: 1.0000\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 1s 23us/step - loss: 5.5102e-06 - acc: 1.0000 - val_loss: 5.8415e-06 - val_acc: 1.0000\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 1s 23us/step - loss: 4.2779e-06 - acc: 1.0000 - val_loss: 4.6294e-06 - val_acc: 1.0000\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 1s 23us/step - loss: 3.3364e-06 - acc: 1.0000 - val_loss: 3.6916e-06 - val_acc: 1.0000\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 2.6183e-06 - acc: 1.0000 - val_loss: 2.9621e-06 - val_acc: 1.0000\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 1s 23us/step - loss: 2.0614e-06 - acc: 1.0000 - val_loss: 2.3804e-06 - val_acc: 1.0000\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 1s 23us/step - loss: 1.6302e-06 - acc: 1.0000 - val_loss: 1.9319e-06 - val_acc: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Architecture</th>\n",
              "      <th>Epoch time</th>\n",
              "      <th>Accuracy Train</th>\n",
              "      <th>Accuracy Test</th>\n",
              "      <th>Loss Train</th>\n",
              "      <th>Loss Test</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>784-256-256-256-256-2</td>\n",
              "      <td>1secs</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.1920928955078125e-07</td>\n",
              "      <td>1.1920928955078125e-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>784-128-128-128-128-2</td>\n",
              "      <td>1secs</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.199682575437085e-07</td>\n",
              "      <td>1.1942386636292213e-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>784-64-64-64-64-2</td>\n",
              "      <td>1secs</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.2025038532404627e-07</td>\n",
              "      <td>1.2082457969881945e-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>784-12-12-12-12-2</td>\n",
              "      <td>1secs</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.4509509328490822e-07</td>\n",
              "      <td>1.517779495316063e-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>784-256-256-256-2</td>\n",
              "      <td>1secs</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.1928478880539236e-07</td>\n",
              "      <td>1.1928081516998645e-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>784-128-128-128-2</td>\n",
              "      <td>1secs</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.2095173860871e-07</td>\n",
              "      <td>1.206219245432294e-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>784-64-64-64-2</td>\n",
              "      <td>1secs</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.2006759756483612e-07</td>\n",
              "      <td>1.2333991935520318e-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>784-12-12-12-2</td>\n",
              "      <td>1secs</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.698952008970082e-07</td>\n",
              "      <td>7.028974341665162e-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>784-256-256-2</td>\n",
              "      <td>1secs</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.1962652273875088e-07</td>\n",
              "      <td>1.1975765355600743e-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>784-128-128-2</td>\n",
              "      <td>1secs</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.2181302442210533e-07</td>\n",
              "      <td>1.2374522316349611e-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>784-64-64-2</td>\n",
              "      <td>1secs</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.201023677519212e-07</td>\n",
              "      <td>1.2378696451378345e-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>784-12-12-2</td>\n",
              "      <td>1secs</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0986857451959317e-07</td>\n",
              "      <td>3.6104356809119054e-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>784-256-2</td>\n",
              "      <td>1secs</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.2958254590860938e-07</td>\n",
              "      <td>1.4220517505236786e-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>784-128-2</td>\n",
              "      <td>1secs</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.2938784180581328e-07</td>\n",
              "      <td>1.38396340298641e-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>784-64-2</td>\n",
              "      <td>1secs</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.333180156005255e-07</td>\n",
              "      <td>4.7241672800737436e-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>784-12-2</td>\n",
              "      <td>1secs</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.4496984953363305e-06</td>\n",
              "      <td>1.931938025472846e-06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Architecture Epoch time Accuracy Train Accuracy Test  \\\n",
              "0   784-256-256-256-256-2      1secs            1.0           1.0   \n",
              "1   784-128-128-128-128-2      1secs            1.0           1.0   \n",
              "2       784-64-64-64-64-2      1secs            1.0           1.0   \n",
              "3       784-12-12-12-12-2      1secs            1.0           1.0   \n",
              "4       784-256-256-256-2      1secs            1.0           1.0   \n",
              "5       784-128-128-128-2      1secs            1.0           1.0   \n",
              "6          784-64-64-64-2      1secs            1.0           1.0   \n",
              "7          784-12-12-12-2      1secs            1.0           1.0   \n",
              "8           784-256-256-2      1secs            1.0           1.0   \n",
              "9           784-128-128-2      1secs            1.0           1.0   \n",
              "10            784-64-64-2      1secs            1.0           1.0   \n",
              "11            784-12-12-2      1secs            1.0           1.0   \n",
              "12              784-256-2      1secs            1.0           1.0   \n",
              "13              784-128-2      1secs            1.0           1.0   \n",
              "14               784-64-2      1secs            1.0           1.0   \n",
              "15               784-12-2      1secs            1.0           1.0   \n",
              "\n",
              "                Loss Train               Loss Test  \n",
              "0   1.1920928955078125e-07  1.1920928955078125e-07  \n",
              "1    1.199682575437085e-07  1.1942386636292213e-07  \n",
              "2   1.2025038532404627e-07  1.2082457969881945e-07  \n",
              "3   1.4509509328490822e-07   1.517779495316063e-07  \n",
              "4   1.1928478880539236e-07  1.1928081516998645e-07  \n",
              "5      1.2095173860871e-07   1.206219245432294e-07  \n",
              "6   1.2006759756483612e-07  1.2333991935520318e-07  \n",
              "7    5.698952008970082e-07   7.028974341665162e-07  \n",
              "8   1.1962652273875088e-07  1.1975765355600743e-07  \n",
              "9   1.2181302442210533e-07  1.2374522316349611e-07  \n",
              "10   1.201023677519212e-07  1.2378696451378345e-07  \n",
              "11  3.0986857451959317e-07  3.6104356809119054e-07  \n",
              "12  1.2958254590860938e-07  1.4220517505236786e-07  \n",
              "13  1.2938784180581328e-07    1.38396340298641e-07  \n",
              "14   3.333180156005255e-07  4.7241672800737436e-07  \n",
              "15  1.4496984953363305e-06   1.931938025472846e-06  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mftPd_HMfG1G",
        "colab_type": "text"
      },
      "source": [
        "# Building CNN model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyW26dcNfG1H",
        "colab_type": "text"
      },
      "source": [
        "Now it's time to build the model step-by-step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SY65TDiVfG1I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_cnn = Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hl10O6QfG1K",
        "colab_type": "text"
      },
      "source": [
        "Out model is going to be *Sequential* which means that every new added layer will be automatically connected to the previous one."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVShkZvufG1K",
        "colab_type": "text"
      },
      "source": [
        "Firstly, let's define hyperparameters of the network:\n",
        "* **filters** $-$ number of filters (or kernels) to use in every layer; in fact this is the same as having multiple channels in the image\n",
        "* **pool_size** $-$ size of the pooling window\n",
        "* **kernel_size** $-$ size of the convolutional filters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azr3pFy8fG1L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filters = 32\n",
        "kernel_size = (3, 3)\n",
        "pool_size = (2, 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jkfz9EPfG1N",
        "colab_type": "text"
      },
      "source": [
        "Now let's add first layer of the network. It is 2D Convolutional layer. Only unexplained thing here is *padding*. This is the parameter that defines how should we pad the data after applying convolutions. $\\text{padding} = \\text{'valid'}$ means that we're not going to pad images and the dimension of it is going to shrink from layer to layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0wuSZkQfG1O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_cnn.add(Convolution2D(filters=filters, \n",
        "                            kernel_size=kernel_size,\n",
        "                            padding=\"valid\",\n",
        "                            input_shape=input_shape))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85XCVwLffG1Q",
        "colab_type": "text"
      },
      "source": [
        "Next step is to add nonlinearity to enable our network to learn complex dependencies. We're going to use ReLU activation function because it is less exposed to vanishing gradient problem and faster to train."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJo5f4JSfG1Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_cnn.add(Activation('relu'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bk3EqbBNfG1S",
        "colab_type": "text"
      },
      "source": [
        "Let's stack one more Convolution layer on top of that:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8b6v1VRfG1T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_cnn.add(Convolution2D(filters=filters, \n",
        "                            kernel_size=kernel_size,\n",
        "                            padding=\"valid\"))\n",
        "model_cnn.add(Activation('relu'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9GcBLU8fG1V",
        "colab_type": "text"
      },
      "source": [
        "Now it's time to apply pooling. Note that the strategies of combining convolutional and pooling layers may be different. For further details see [here](http://cs231n.stanford.edu/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKDyp4e-fG1X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_cnn.add(MaxPooling2D(pool_size=pool_size))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58bYH49LfG1Z",
        "colab_type": "text"
      },
      "source": [
        "At this point we consider that we've already distinguish some meaningful features from the pictures. So it's time to classify them. For that purpose the common approach is to append fully-connected part. \n",
        "\n",
        "But before that we need to pull all the obtained feature into one vector so that one object has 1D-vector of features. It is done by means of $\\text{Flatten}$ layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7S1Ad5pfG1a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_cnn.add(Flatten())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IF3YzCUQfG1d",
        "colab_type": "text"
      },
      "source": [
        "Now let's add FC part with the [dropout](https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf) to avoid overfitting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqrWHfmjfG1d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_cnn.add(Dropout(0.5))\n",
        "model_cnn.add(Dense(128, activation=\"relu\"))\n",
        "model_cnn.add(Dropout(0.5))\n",
        "model_cnn.add(Dense(nb_classes, activation=\"softmax\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlvxDI9qfG1f",
        "colab_type": "text"
      },
      "source": [
        "The final layer here is usual $\\text{Softmax}$ with the number of classe. So as the output of the network we observe the probability of each class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nx4im2eOfG1g",
        "colab_type": "text"
      },
      "source": [
        "Now let's compile our model.\n",
        "* **optimizer** $-$ here we use accelerated gradient descent algorithm with special adaptive way of choosing learning rate; for more details see this great [overview](http://sebastianruder.com/optimizing-gradient-descent/) of gradient descent optimization algorithms.\n",
        "* **loss** $-$ usual choice for multiclass classification is softmax output layer in combination with categotical crossentropy loss function which is\n",
        "$$\n",
        "\\mathcal{L}(\\text{true}, \\text{pred}) = -\\sum_{j=1}^{k}\\text{true}_j \\cdot \\log \\{\\text{pred}_j\\}\n",
        "$$\n",
        "* **metrics** $-$ additional metrics that we're going to trace while training; it doesn't influence training process at all"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzYWVI9LfG1h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_cnn.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IW9sFyubfG1j",
        "colab_type": "text"
      },
      "source": [
        "Let's take a look at our final model now:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZeQAM6YrfG1k",
        "colab_type": "code",
        "outputId": "b4ae5869-5b3a-4956-c71b-fc101a9ca74b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        }
      },
      "source": [
        "model_cnn.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 26, 26, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 24, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 24, 24, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 4608)              0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 4608)              0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 128)               589952    \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 600,810\n",
            "Trainable params: 600,810\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fp34NZXNfG1r",
        "colab_type": "code",
        "outputId": "5b4937cc-9977-42db-bd99-da50f2cdd711",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1188
        }
      },
      "source": [
        "SVG(model_to_dot(model_cnn, show_shapes=True).create(prog='dot', format='svg'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"875pt\" viewBox=\"0.00 0.00 412.00 875.00\" width=\"412pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 871)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-871 408,-871 408,4 -4,4\" stroke=\"transparent\"/>\n<!-- 139973340763976 -->\n<g class=\"node\" id=\"node1\">\n<title>139973340763976</title>\n<polygon fill=\"none\" points=\"44,-747.5 44,-793.5 360,-793.5 360,-747.5 44,-747.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110.5\" y=\"-766.8\">conv2d_1: Conv2D</text>\n<polyline fill=\"none\" points=\"177,-747.5 177,-793.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"206\" y=\"-778.3\">input:</text>\n<polyline fill=\"none\" points=\"177,-770.5 235,-770.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"206\" y=\"-755.3\">output:</text>\n<polyline fill=\"none\" points=\"235,-747.5 235,-793.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"297.5\" y=\"-778.3\">(None, 28, 28, 1)</text>\n<polyline fill=\"none\" points=\"235,-770.5 360,-770.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"297.5\" y=\"-755.3\">(None, 26, 26, 32)</text>\n</g>\n<!-- 139973340763920 -->\n<g class=\"node\" id=\"node2\">\n<title>139973340763920</title>\n<polygon fill=\"none\" points=\"33.5,-664.5 33.5,-710.5 370.5,-710.5 370.5,-664.5 33.5,-664.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110.5\" y=\"-683.8\">activation_1: Activation</text>\n<polyline fill=\"none\" points=\"187.5,-664.5 187.5,-710.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"216.5\" y=\"-695.3\">input:</text>\n<polyline fill=\"none\" points=\"187.5,-687.5 245.5,-687.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"216.5\" y=\"-672.3\">output:</text>\n<polyline fill=\"none\" points=\"245.5,-664.5 245.5,-710.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"308\" y=\"-695.3\">(None, 26, 26, 32)</text>\n<polyline fill=\"none\" points=\"245.5,-687.5 370.5,-687.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"308\" y=\"-672.3\">(None, 26, 26, 32)</text>\n</g>\n<!-- 139973340763976&#45;&gt;139973340763920 -->\n<g class=\"edge\" id=\"edge2\">\n<title>139973340763976-&gt;139973340763920</title>\n<path d=\"M202,-747.3799C202,-739.1745 202,-729.7679 202,-720.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"205.5001,-720.784 202,-710.784 198.5001,-720.784 205.5001,-720.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139973340834168 -->\n<g class=\"node\" id=\"node3\">\n<title>139973340834168</title>\n<polygon fill=\"none\" points=\"44,-581.5 44,-627.5 360,-627.5 360,-581.5 44,-581.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110.5\" y=\"-600.8\">conv2d_2: Conv2D</text>\n<polyline fill=\"none\" points=\"177,-581.5 177,-627.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"206\" y=\"-612.3\">input:</text>\n<polyline fill=\"none\" points=\"177,-604.5 235,-604.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"206\" y=\"-589.3\">output:</text>\n<polyline fill=\"none\" points=\"235,-581.5 235,-627.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"297.5\" y=\"-612.3\">(None, 26, 26, 32)</text>\n<polyline fill=\"none\" points=\"235,-604.5 360,-604.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"297.5\" y=\"-589.3\">(None, 24, 24, 32)</text>\n</g>\n<!-- 139973340763920&#45;&gt;139973340834168 -->\n<g class=\"edge\" id=\"edge3\">\n<title>139973340763920-&gt;139973340834168</title>\n<path d=\"M202,-664.3799C202,-656.1745 202,-646.7679 202,-637.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"205.5001,-637.784 202,-627.784 198.5001,-637.784 205.5001,-637.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139973340835288 -->\n<g class=\"node\" id=\"node4\">\n<title>139973340835288</title>\n<polygon fill=\"none\" points=\"33.5,-498.5 33.5,-544.5 370.5,-544.5 370.5,-498.5 33.5,-498.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110.5\" y=\"-517.8\">activation_2: Activation</text>\n<polyline fill=\"none\" points=\"187.5,-498.5 187.5,-544.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"216.5\" y=\"-529.3\">input:</text>\n<polyline fill=\"none\" points=\"187.5,-521.5 245.5,-521.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"216.5\" y=\"-506.3\">output:</text>\n<polyline fill=\"none\" points=\"245.5,-498.5 245.5,-544.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"308\" y=\"-529.3\">(None, 24, 24, 32)</text>\n<polyline fill=\"none\" points=\"245.5,-521.5 370.5,-521.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"308\" y=\"-506.3\">(None, 24, 24, 32)</text>\n</g>\n<!-- 139973340834168&#45;&gt;139973340835288 -->\n<g class=\"edge\" id=\"edge4\">\n<title>139973340834168-&gt;139973340835288</title>\n<path d=\"M202,-581.3799C202,-573.1745 202,-563.7679 202,-554.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"205.5001,-554.784 202,-544.784 198.5001,-554.784 205.5001,-554.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139973340834000 -->\n<g class=\"node\" id=\"node5\">\n<title>139973340834000</title>\n<polygon fill=\"none\" points=\"0,-415.5 0,-461.5 404,-461.5 404,-415.5 0,-415.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110.5\" y=\"-434.8\">max_pooling2d_1: MaxPooling2D</text>\n<polyline fill=\"none\" points=\"221,-415.5 221,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"250\" y=\"-446.3\">input:</text>\n<polyline fill=\"none\" points=\"221,-438.5 279,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"250\" y=\"-423.3\">output:</text>\n<polyline fill=\"none\" points=\"279,-415.5 279,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"341.5\" y=\"-446.3\">(None, 24, 24, 32)</text>\n<polyline fill=\"none\" points=\"279,-438.5 404,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"341.5\" y=\"-423.3\">(None, 12, 12, 32)</text>\n</g>\n<!-- 139973340835288&#45;&gt;139973340834000 -->\n<g class=\"edge\" id=\"edge5\">\n<title>139973340835288-&gt;139973340834000</title>\n<path d=\"M202,-498.3799C202,-490.1745 202,-480.7679 202,-471.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"205.5001,-471.784 202,-461.784 198.5001,-471.784 205.5001,-471.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139973340764704 -->\n<g class=\"node\" id=\"node6\">\n<title>139973340764704</title>\n<polygon fill=\"none\" points=\"54,-332.5 54,-378.5 350,-378.5 350,-332.5 54,-332.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110.5\" y=\"-351.8\">flatten_1: Flatten</text>\n<polyline fill=\"none\" points=\"167,-332.5 167,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"196\" y=\"-363.3\">input:</text>\n<polyline fill=\"none\" points=\"167,-355.5 225,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"196\" y=\"-340.3\">output:</text>\n<polyline fill=\"none\" points=\"225,-332.5 225,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"287.5\" y=\"-363.3\">(None, 12, 12, 32)</text>\n<polyline fill=\"none\" points=\"225,-355.5 350,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"287.5\" y=\"-340.3\">(None, 4608)</text>\n</g>\n<!-- 139973340834000&#45;&gt;139973340764704 -->\n<g class=\"edge\" id=\"edge6\">\n<title>139973340834000-&gt;139973340764704</title>\n<path d=\"M202,-415.3799C202,-407.1745 202,-397.7679 202,-388.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"205.5001,-388.784 202,-378.784 198.5001,-388.784 205.5001,-388.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139973340147784 -->\n<g class=\"node\" id=\"node7\">\n<title>139973340147784</title>\n<polygon fill=\"none\" points=\"58.5,-249.5 58.5,-295.5 345.5,-295.5 345.5,-249.5 58.5,-249.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"125.5\" y=\"-268.8\">dropout_4: Dropout</text>\n<polyline fill=\"none\" points=\"192.5,-249.5 192.5,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"221.5\" y=\"-280.3\">input:</text>\n<polyline fill=\"none\" points=\"192.5,-272.5 250.5,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"221.5\" y=\"-257.3\">output:</text>\n<polyline fill=\"none\" points=\"250.5,-249.5 250.5,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"298\" y=\"-280.3\">(None, 4608)</text>\n<polyline fill=\"none\" points=\"250.5,-272.5 345.5,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"298\" y=\"-257.3\">(None, 4608)</text>\n</g>\n<!-- 139973340764704&#45;&gt;139973340147784 -->\n<g class=\"edge\" id=\"edge7\">\n<title>139973340764704-&gt;139973340147784</title>\n<path d=\"M202,-332.3799C202,-324.1745 202,-314.7679 202,-305.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"205.5001,-305.784 202,-295.784 198.5001,-305.784 205.5001,-305.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139973340569552 -->\n<g class=\"node\" id=\"node8\">\n<title>139973340569552</title>\n<polygon fill=\"none\" points=\"72,-166.5 72,-212.5 332,-212.5 332,-166.5 72,-166.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"125.5\" y=\"-185.8\">dense_5: Dense</text>\n<polyline fill=\"none\" points=\"179,-166.5 179,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"208\" y=\"-197.3\">input:</text>\n<polyline fill=\"none\" points=\"179,-189.5 237,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"208\" y=\"-174.3\">output:</text>\n<polyline fill=\"none\" points=\"237,-166.5 237,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"284.5\" y=\"-197.3\">(None, 4608)</text>\n<polyline fill=\"none\" points=\"237,-189.5 332,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"284.5\" y=\"-174.3\">(None, 128)</text>\n</g>\n<!-- 139973340147784&#45;&gt;139973340569552 -->\n<g class=\"edge\" id=\"edge8\">\n<title>139973340147784-&gt;139973340569552</title>\n<path d=\"M202,-249.3799C202,-241.1745 202,-231.7679 202,-222.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"205.5001,-222.784 202,-212.784 198.5001,-222.784 205.5001,-222.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139973340147952 -->\n<g class=\"node\" id=\"node9\">\n<title>139973340147952</title>\n<polygon fill=\"none\" points=\"62.5,-83.5 62.5,-129.5 341.5,-129.5 341.5,-83.5 62.5,-83.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"129.5\" y=\"-102.8\">dropout_5: Dropout</text>\n<polyline fill=\"none\" points=\"196.5,-83.5 196.5,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"225.5\" y=\"-114.3\">input:</text>\n<polyline fill=\"none\" points=\"196.5,-106.5 254.5,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"225.5\" y=\"-91.3\">output:</text>\n<polyline fill=\"none\" points=\"254.5,-83.5 254.5,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"298\" y=\"-114.3\">(None, 128)</text>\n<polyline fill=\"none\" points=\"254.5,-106.5 341.5,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"298\" y=\"-91.3\">(None, 128)</text>\n</g>\n<!-- 139973340569552&#45;&gt;139973340147952 -->\n<g class=\"edge\" id=\"edge9\">\n<title>139973340569552-&gt;139973340147952</title>\n<path d=\"M202,-166.3799C202,-158.1745 202,-148.7679 202,-139.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"205.5001,-139.784 202,-129.784 198.5001,-139.784 205.5001,-139.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139973340150304 -->\n<g class=\"node\" id=\"node10\">\n<title>139973340150304</title>\n<polygon fill=\"none\" points=\"76,-.5 76,-46.5 328,-46.5 328,-.5 76,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"129.5\" y=\"-19.8\">dense_6: Dense</text>\n<polyline fill=\"none\" points=\"183,-.5 183,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"212\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"183,-23.5 241,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"212\" y=\"-8.3\">output:</text>\n<polyline fill=\"none\" points=\"241,-.5 241,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"284.5\" y=\"-31.3\">(None, 128)</text>\n<polyline fill=\"none\" points=\"241,-23.5 328,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"284.5\" y=\"-8.3\">(None, 10)</text>\n</g>\n<!-- 139973340147952&#45;&gt;139973340150304 -->\n<g class=\"edge\" id=\"edge10\">\n<title>139973340147952-&gt;139973340150304</title>\n<path d=\"M202,-83.3799C202,-75.1745 202,-65.7679 202,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"205.5001,-56.784 202,-46.784 198.5001,-56.784 205.5001,-56.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139973340764368 -->\n<g class=\"node\" id=\"node11\">\n<title>139973340764368</title>\n<polygon fill=\"none\" points=\"137.5,-830.5 137.5,-866.5 266.5,-866.5 266.5,-830.5 137.5,-830.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"202\" y=\"-844.8\">139973340764368</text>\n</g>\n<!-- 139973340764368&#45;&gt;139973340763976 -->\n<g class=\"edge\" id=\"edge1\">\n<title>139973340764368-&gt;139973340763976</title>\n<path d=\"M202,-830.4092C202,-822.4308 202,-812.795 202,-803.606\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"205.5001,-803.5333 202,-793.5333 198.5001,-803.5334 205.5001,-803.5333\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZLhafUefG1v",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D94UPnpHfG1x",
        "colab_type": "text"
      },
      "source": [
        "Training parameters are the following:\n",
        "* nb_epoch $-$ number of epochs to train. here we choose 12; one may condiser using some stopping criterias\n",
        "* **batch_size** $-$ parameter that controls how frequent do we update gradient; with $\\text{batch_size}=1$ optimization is nothing but pure Stohastic Gradient Descent (update gradient after passing each one object); with $\\text{batch_size}=\\textit{number of objects}$ it will be usual Gradient Descent which updates gradient only after passing all objects. Choosing value between this two one can control speed and convergence of training process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3bqDUNofG1y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZC0Iw8RjfG11",
        "colab_type": "text"
      },
      "source": [
        "Train!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dp9uLCj4fG12",
        "colab_type": "code",
        "outputId": "fd5a3371-c36c-4805-c453-8e0b925bbed9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "hist = model_cnn.fit(X_train, y_train, \n",
        "                     batch_size=batch_size, \n",
        "                     epochs=epochs,\n",
        "                     validation_data=(X_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 117s 2ms/step - loss: 0.3019 - acc: 0.9076 - val_loss: 0.0622 - val_acc: 0.9803\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 117s 2ms/step - loss: 0.1086 - acc: 0.9679 - val_loss: 0.0464 - val_acc: 0.9851\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 116s 2ms/step - loss: 0.0864 - acc: 0.9739 - val_loss: 0.0394 - val_acc: 0.9877\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 116s 2ms/step - loss: 0.0717 - acc: 0.9784 - val_loss: 0.0350 - val_acc: 0.9882\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 117s 2ms/step - loss: 0.0649 - acc: 0.9797 - val_loss: 0.0337 - val_acc: 0.9891\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-djY_7-fG15",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIoB6lRlfG15",
        "colab_type": "text"
      },
      "source": [
        "Visualization of learning process:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHcPw53FfG16",
        "colab_type": "code",
        "outputId": "f4fefb34-2954-45f3-cad0-619622d3aa9b",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(20, 8))\n",
        "plt.suptitle(\"CNN model training\", fontsize=18)\n",
        "plt.subplot(121)\n",
        "plt.plot(hist.history[\"loss\"], label=\"Train\")\n",
        "plt.plot(hist.history[\"val_loss\"], label=\"Test\")\n",
        "plt.grid(\"on\")\n",
        "plt.xlabel(\"Epoch\", fontsize=14)\n",
        "plt.ylabel(\"Crossentropy\", fontsize=14)\n",
        "plt.legend(loc=\"upper right\")\n",
        "plt.subplot(122)\n",
        "plt.plot(hist.history[\"acc\"], label=\"Train\")\n",
        "plt.grid(\"on\")\n",
        "plt.plot(hist.history[\"val_acc\"], label=\"Test\")\n",
        "plt.xlabel(\"Epoch\", fontsize=14)\n",
        "plt.ylabel(\"Accuracy\", fontsize=14)\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.ylim([0.88, 1.0]);"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABKAAAAIgCAYAAACyORFeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n7poAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f5ce2f15080>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2hJy8AsfG1_",
        "colab_type": "text"
      },
      "source": [
        "Final evaluation of the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVMTvEC_fG2A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score_train = model_cnn.evaluate(X_train, y_train, verbose=0)\n",
        "score_test = model_cnn.evaluate(X_test, y_test, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVLQZKJOfG2D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results.loc[len(results)] = np.array([score_train[1], score_test[1], score_train[0], score_test[0]])\n",
        "results.index = [\"MLP\", \"CNN\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVacHrLZfG2G",
        "colab_type": "code",
        "outputId": "c98f1738-90ae-4a7b-e5d0-65be1da2bfa9",
        "colab": {}
      },
      "source": [
        "results"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style>\n",
              "    .dataframe thead tr:only-child th {\n",
              "        text-align: right;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy Train</th>\n",
              "      <th>Accuracy Test</th>\n",
              "      <th>Loss Train</th>\n",
              "      <th>Loss Test</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>MLP</th>\n",
              "      <td>0.9862</td>\n",
              "      <td>0.9746</td>\n",
              "      <td>0.045773</td>\n",
              "      <td>0.090305</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CNN</th>\n",
              "      <td>0.9934</td>\n",
              "      <td>0.9883</td>\n",
              "      <td>0.021616</td>\n",
              "      <td>0.032652</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Accuracy Train  Accuracy Test  Loss Train  Loss Test\n",
              "MLP          0.9862         0.9746    0.045773   0.090305\n",
              "CNN          0.9934         0.9883    0.021616   0.032652"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GiJMC-NmfG2J",
        "colab_type": "text"
      },
      "source": [
        "# Task: choose a better architecture\n",
        "\n",
        "Search for a good CNN architecture to model the MNIST problem.\n",
        "\n",
        "\n",
        "**Test:train:validation:** Keep the test dataset as a held out dataset to report your final results. Use 20% of the training as your validation set and make all decisions regarding  architecture choices using the validation set (or subsets of the original training set).  \n",
        "\n",
        "It is up to you what the model will be. Here are some things you need to decide:\n",
        "* how many convolutional layers?\n",
        "* what spatial size will your convolutions be?\n",
        "* how many channels will your convolutions be?\n",
        "* what nonlinearity will you use?\n",
        "* will you use pooling? what type?\n",
        "* how many fully-connected layers will you have?\n",
        "* will you use dropout?\n",
        "* what batch size?\n",
        "\n",
        "Keras provides a special layer called `Flatten` to flatten the convolutional features into a vector before the fully-connected layers. You should look at the documentation for Keras's convolutional layers: http://keras.io/layers/convolutional/. In particular, you may want to look at `Convolution2D`, `MaxPooling2D`, `AveragePooling2D`, `Flatten`, and `Dropout`. For this problem, you make want to use the `'rmsprop'` optimizer - it is an algorithm that adapts the learning rate during learning for you automatically.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqXUyyZ_fG2L",
        "colab_type": "text"
      },
      "source": [
        "## load MNIST data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrCxDBfTfG2M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import keras.backend as K\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential, Model, load_model\n",
        "from keras.layers import Dense, Input\n",
        "from keras.layers.merge import Concatenate\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.initializers import he_normal\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from IPython.display import SVG\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zr_a7ZOyfG2O",
        "colab_type": "code",
        "outputId": "2b98ff2b-77e7-4b02-981b-8eb0674eb1b2",
        "colab": {}
      },
      "source": [
        "# load MNIST data\n",
        "from sklearn.model_selection import train_test_split\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.20, random_state=42)\n",
        "img_rows, img_cols = 28, 28\n",
        "number_of_classes = 10\n",
        "print(f\"X before flatten train      shape: {X_train.shape}\")\n",
        "print(f\"X before flatten validation shape: {X_valid.shape}\")\n",
        "print(f\"X before flatten test       shape: {X_test.shape}\")\n",
        "#Here we're going to use dense baseline models so we need to represent our data as 1-dimensional vectors\n",
        "if K.image_dim_ordering() == 'th':\n",
        "    X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n",
        "    X_valid = X_test.reshape(X_valid.shape[0], 1, img_rows, img_cols)\n",
        "    X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
        "    X_valid = X_valid.reshape(X_valid.shape[0], img_rows, img_cols, 1)\n",
        "    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "#Tensorflow prefers to work with float32 data type. \n",
        "#So the next step is to cast data. \n",
        "# Also let's have our data in [0; 1]interval; it's common choice for grayscale images.\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "X_valid = X_valid.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_valid /= 255\n",
        "X_test /= 255\n",
        "print(f\"X train      shape: {X_train.shape}, {y_train.shape}\")\n",
        "print(f\"X validation shape: {X_valid.shape},  {y_valid.shape}\")\n",
        "print(f\"X test       shape: {X_test.shape},  {y_test.shape}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X before flatten train      shape: (48000, 28, 28)\n",
            "X before flatten validation shape: (12000, 28, 28)\n",
            "X before flatten test       shape: (10000, 28, 28)\n",
            "X train      shape: (48000, 28, 28, 1), (48000,)\n",
            "X validation shape: (12000, 28, 28, 1),  (12000,)\n",
            "X test       shape: (10000, 28, 28, 1),  (10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUF-SqMEfG2Q",
        "colab_type": "text"
      },
      "source": [
        "## Setup the MNIST data\n",
        "Setup the MNIST data. Here we use  **digits 0 to 9**. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWgNmAoGfG2R",
        "colab_type": "text"
      },
      "source": [
        "Convert labels into [One-Hot Encoding](https://en.wikipedia.org/wiki/One-hot) because we're going to learn them through the softmax layer of CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93Lw0g03fG2S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = to_categorical(y_train, number_of_classes)\n",
        "y_valid = to_categorical(y_valid, number_of_classes)\n",
        "y_test  = to_categorical(y_test, number_of_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TO4Y0yQEfG2V",
        "colab_type": "code",
        "outputId": "be893a43-07c7-40ef-ff80-4b011e3abc42",
        "colab": {}
      },
      "source": [
        "print(f\"X train      shape: {X_train.shape}, {y_train.shape}\")\n",
        "print(f\"X validation shape: {X_valid.shape},  {y_valid.shape}\")\n",
        "print(f\"X test       shape: {X_test.shape},  {y_test.shape}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X train      shape: (48000, 28, 28, 1), (48000, 10)\n",
            "X validation shape: (12000, 28, 28, 1),  (12000, 10)\n",
            "X test       shape: (10000, 28, 28, 1),  (10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivlynAgPfG2Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mj9bTrUKfG2b",
        "colab_type": "code",
        "outputId": "16eeadba-b9cd-4a4a-902a-0ec46f80b3e3",
        "colab": {}
      },
      "source": [
        "    \n",
        "num_classes = y_test.shape[1]\n",
        "model = Sequential()\n",
        "model.add(Convolution2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu', padding=\"valid\",\n",
        "                 input_shape=input_shape))  #r, c, depth\n",
        "model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_20 (Conv2D)           (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_21 (Conv2D)           (None, 24, 24, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_20 (Dropout)         (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_9 (Flatten)          (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 128)               1179776   \n",
            "_________________________________________________________________\n",
            "dropout_21 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 1,199,882\n",
            "Trainable params: 1,199,882\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GtILnucfG2e",
        "colab_type": "code",
        "outputId": "ce2903e9-7f2b-4edc-e0f0-0bb6531d1b35",
        "colab": {}
      },
      "source": [
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "\n",
        "SVG(model_to_dot(model, show_shapes=True, ).create(prog=\"dot\", format=\"svg\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/svg+xml": "<svg height=\"738pt\" viewBox=\"0.00 0.00 393.92 737.80\" width=\"394pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 733.8)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-733.8 389.9208,-733.8 389.9208,4 -4,4\" stroke=\"transparent\"/>\n<!-- 139837439246912 -->\n<g class=\"node\" id=\"node1\">\n<title>139837439246912</title>\n<polygon fill=\"none\" points=\"39.2791,-606.7 39.2791,-656.3 346.6417,-656.3 346.6417,-606.7 39.2791,-606.7\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"105.8033\" y=\"-627.3\">conv2d_20: Conv2D</text>\n<polyline fill=\"none\" points=\"172.3275,-606.7 172.3275,-656.3 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"200.1634\" y=\"-639.7\">input:</text>\n<polyline fill=\"none\" points=\"172.3275,-631.5 227.9993,-631.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"200.1634\" y=\"-614.9\">output:</text>\n<polyline fill=\"none\" points=\"227.9993,-606.7 227.9993,-656.3 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"287.3205\" y=\"-639.7\">(None, 28, 28, 1)</text>\n<polyline fill=\"none\" points=\"227.9993,-631.5 346.6417,-631.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"287.3205\" y=\"-614.9\">(None, 26, 26, 32)</text>\n</g>\n<!-- 139837439264864 -->\n<g class=\"node\" id=\"node2\">\n<title>139837439264864</title>\n<polygon fill=\"none\" points=\"39.2791,-520.1 39.2791,-569.7 346.6417,-569.7 346.6417,-520.1 39.2791,-520.1\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"105.8033\" y=\"-540.7\">conv2d_21: Conv2D</text>\n<polyline fill=\"none\" points=\"172.3275,-520.1 172.3275,-569.7 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"200.1634\" y=\"-553.1\">input:</text>\n<polyline fill=\"none\" points=\"172.3275,-544.9 227.9993,-544.9 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"200.1634\" y=\"-528.3\">output:</text>\n<polyline fill=\"none\" points=\"227.9993,-520.1 227.9993,-569.7 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"287.3205\" y=\"-553.1\">(None, 26, 26, 32)</text>\n<polyline fill=\"none\" points=\"227.9993,-544.9 346.6417,-544.9 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"287.3205\" y=\"-528.3\">(None, 24, 24, 64)</text>\n</g>\n<!-- 139837439246912&#45;&gt;139837439264864 -->\n<g class=\"edge\" id=\"edge2\">\n<title>139837439246912-&gt;139837439264864</title>\n<path d=\"M192.9604,-606.4517C192.9604,-598.1937 192.9604,-588.8517 192.9604,-579.9864\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"196.4605,-579.892 192.9604,-569.892 189.4605,-579.892 196.4605,-579.892\" stroke=\"#000000\"/>\n</g>\n<!-- 139837439764240 -->\n<g class=\"node\" id=\"node3\">\n<title>139837439764240</title>\n<polygon fill=\"none\" points=\"0,-433.5 0,-483.1 385.9208,-483.1 385.9208,-433.5 0,-433.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"105.8033\" y=\"-454.1\">max_pooling2d_9: MaxPooling2D</text>\n<polyline fill=\"none\" points=\"211.6066,-433.5 211.6066,-483.1 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"239.4425\" y=\"-466.5\">input:</text>\n<polyline fill=\"none\" points=\"211.6066,-458.3 267.2784,-458.3 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"239.4425\" y=\"-441.7\">output:</text>\n<polyline fill=\"none\" points=\"267.2784,-433.5 267.2784,-483.1 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"326.5996\" y=\"-466.5\">(None, 24, 24, 64)</text>\n<polyline fill=\"none\" points=\"267.2784,-458.3 385.9208,-458.3 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"326.5996\" y=\"-441.7\">(None, 12, 12, 64)</text>\n</g>\n<!-- 139837439264864&#45;&gt;139837439764240 -->\n<g class=\"edge\" id=\"edge3\">\n<title>139837439264864-&gt;139837439764240</title>\n<path d=\"M192.9604,-519.8517C192.9604,-511.5937 192.9604,-502.2517 192.9604,-493.3864\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"196.4605,-493.292 192.9604,-483.292 189.4605,-493.292 196.4605,-493.292\" stroke=\"#000000\"/>\n</g>\n<!-- 139837439246688 -->\n<g class=\"node\" id=\"node4\">\n<title>139837439246688</title>\n<polygon fill=\"none\" points=\"38.5035,-346.9 38.5035,-396.5 347.4173,-396.5 347.4173,-346.9 38.5035,-346.9\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"105.8033\" y=\"-367.5\">dropout_20: Dropout</text>\n<polyline fill=\"none\" points=\"173.1031,-346.9 173.1031,-396.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"200.939\" y=\"-379.9\">input:</text>\n<polyline fill=\"none\" points=\"173.1031,-371.7 228.7749,-371.7 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"200.939\" y=\"-355.1\">output:</text>\n<polyline fill=\"none\" points=\"228.7749,-346.9 228.7749,-396.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"288.0961\" y=\"-379.9\">(None, 12, 12, 64)</text>\n<polyline fill=\"none\" points=\"228.7749,-371.7 347.4173,-371.7 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"288.0961\" y=\"-355.1\">(None, 12, 12, 64)</text>\n</g>\n<!-- 139837439764240&#45;&gt;139837439246688 -->\n<g class=\"edge\" id=\"edge4\">\n<title>139837439764240-&gt;139837439246688</title>\n<path d=\"M192.9604,-433.2517C192.9604,-424.9937 192.9604,-415.6517 192.9604,-406.7864\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"196.4605,-406.692 192.9604,-396.692 189.4605,-406.692 196.4605,-406.692\" stroke=\"#000000\"/>\n</g>\n<!-- 139837439750664 -->\n<g class=\"node\" id=\"node5\">\n<title>139837439750664</title>\n<polygon fill=\"none\" points=\"49.7854,-260.3 49.7854,-309.9 336.1354,-309.9 336.1354,-260.3 49.7854,-260.3\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"105.8033\" y=\"-280.9\">flatten_9: Flatten</text>\n<polyline fill=\"none\" points=\"161.8212,-260.3 161.8212,-309.9 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"189.6571\" y=\"-293.3\">input:</text>\n<polyline fill=\"none\" points=\"161.8212,-285.1 217.493,-285.1 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"189.6571\" y=\"-268.5\">output:</text>\n<polyline fill=\"none\" points=\"217.493,-260.3 217.493,-309.9 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"276.8142\" y=\"-293.3\">(None, 12, 12, 64)</text>\n<polyline fill=\"none\" points=\"217.493,-285.1 336.1354,-285.1 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"276.8142\" y=\"-268.5\">(None, 9216)</text>\n</g>\n<!-- 139837439246688&#45;&gt;139837439750664 -->\n<g class=\"edge\" id=\"edge5\">\n<title>139837439246688-&gt;139837439750664</title>\n<path d=\"M192.9604,-346.6517C192.9604,-338.3937 192.9604,-329.0517 192.9604,-320.1864\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"196.4605,-320.092 192.9604,-310.092 189.4605,-320.092 196.4605,-320.092\" stroke=\"#000000\"/>\n</g>\n<!-- 139837439752400 -->\n<g class=\"node\" id=\"node6\">\n<title>139837439752400</title>\n<polygon fill=\"none\" points=\"64.1809,-173.7 64.1809,-223.3 321.7399,-223.3 321.7399,-173.7 64.1809,-173.7\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"119.8033\" y=\"-194.3\">dense_20: Dense</text>\n<polyline fill=\"none\" points=\"175.4257,-173.7 175.4257,-223.3 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"203.2616\" y=\"-206.7\">input:</text>\n<polyline fill=\"none\" points=\"175.4257,-198.5 231.0975,-198.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"203.2616\" y=\"-181.9\">output:</text>\n<polyline fill=\"none\" points=\"231.0975,-173.7 231.0975,-223.3 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"276.4187\" y=\"-206.7\">(None, 9216)</text>\n<polyline fill=\"none\" points=\"231.0975,-198.5 321.7399,-198.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"276.4187\" y=\"-181.9\">(None, 128)</text>\n</g>\n<!-- 139837439750664&#45;&gt;139837439752400 -->\n<g class=\"edge\" id=\"edge6\">\n<title>139837439750664-&gt;139837439752400</title>\n<path d=\"M192.9604,-260.0517C192.9604,-251.7937 192.9604,-242.4517 192.9604,-233.5864\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"196.4605,-233.492 192.9604,-223.492 189.4605,-233.492 196.4605,-233.492\" stroke=\"#000000\"/>\n</g>\n<!-- 139837439744264 -->\n<g class=\"node\" id=\"node7\">\n<title>139837439744264</title>\n<polygon fill=\"none\" points=\"56.0035,-87.1 56.0035,-136.7 329.9173,-136.7 329.9173,-87.1 56.0035,-87.1\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"123.3033\" y=\"-107.7\">dropout_21: Dropout</text>\n<polyline fill=\"none\" points=\"190.6031,-87.1 190.6031,-136.7 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"218.439\" y=\"-120.1\">input:</text>\n<polyline fill=\"none\" points=\"190.6031,-111.9 246.2749,-111.9 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"218.439\" y=\"-95.3\">output:</text>\n<polyline fill=\"none\" points=\"246.2749,-87.1 246.2749,-136.7 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"288.0961\" y=\"-120.1\">(None, 128)</text>\n<polyline fill=\"none\" points=\"246.2749,-111.9 329.9173,-111.9 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"288.0961\" y=\"-95.3\">(None, 128)</text>\n</g>\n<!-- 139837439752400&#45;&gt;139837439744264 -->\n<g class=\"edge\" id=\"edge7\">\n<title>139837439752400-&gt;139837439744264</title>\n<path d=\"M192.9604,-173.4517C192.9604,-165.1937 192.9604,-155.8517 192.9604,-146.9864\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"196.4605,-146.892 192.9604,-136.892 189.4605,-146.892 196.4605,-146.892\" stroke=\"#000000\"/>\n</g>\n<!-- 139837439540528 -->\n<g class=\"node\" id=\"node8\">\n<title>139837439540528</title>\n<polygon fill=\"none\" points=\"67.6809,-.5 67.6809,-50.1 318.2399,-50.1 318.2399,-.5 67.6809,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"123.3033\" y=\"-21.1\">dense_21: Dense</text>\n<polyline fill=\"none\" points=\"178.9257,-.5 178.9257,-50.1 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"206.7616\" y=\"-33.5\">input:</text>\n<polyline fill=\"none\" points=\"178.9257,-25.3 234.5975,-25.3 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"206.7616\" y=\"-8.7\">output:</text>\n<polyline fill=\"none\" points=\"234.5975,-.5 234.5975,-50.1 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"276.4187\" y=\"-33.5\">(None, 128)</text>\n<polyline fill=\"none\" points=\"234.5975,-25.3 318.2399,-25.3 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"276.4187\" y=\"-8.7\">(None, 10)</text>\n</g>\n<!-- 139837439744264&#45;&gt;139837439540528 -->\n<g class=\"edge\" id=\"edge8\">\n<title>139837439744264-&gt;139837439540528</title>\n<path d=\"M192.9604,-86.8517C192.9604,-78.5937 192.9604,-69.2517 192.9604,-60.3864\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"196.4605,-60.292 192.9604,-50.292 189.4605,-60.292 196.4605,-60.292\" stroke=\"#000000\"/>\n</g>\n<!-- 139837439246576 -->\n<g class=\"node\" id=\"node9\">\n<title>139837439246576</title>\n<polygon fill=\"none\" points=\"132.4604,-693.3 132.4604,-729.3 253.4604,-729.3 253.4604,-693.3 132.4604,-693.3\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"192.9604\" y=\"-707.1\">139837439246576</text>\n</g>\n<!-- 139837439246576&#45;&gt;139837439246912 -->\n<g class=\"edge\" id=\"edge1\">\n<title>139837439246576-&gt;139837439246912</title>\n<path d=\"M192.9604,-693.1921C192.9604,-685.3071 192.9604,-675.7843 192.9604,-666.6049\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"196.4605,-666.4927 192.9604,-656.4927 189.4605,-666.4927 196.4605,-666.4927\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>",
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdI-hn9RfG2k",
        "colab_type": "text"
      },
      "source": [
        "### Early stopping callback:\n",
        "* **monitor = \"val_loss\"** means that we're going to trace validation categorical crossentropy loss\n",
        "* **patience = 3** shows how many epochs without improvement can we wait for until stop training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwtQiKEffG2k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "es = EarlyStopping(monitor=\"val_loss\", patience=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "290E1ag2fG2l",
        "colab_type": "text"
      },
      "source": [
        "### Model checkpoint callback"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWBA8-r5fG2m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mc = ModelCheckpoint(filepath=\"./chkpt\", \n",
        "                     monitor=\"val_loss\", \n",
        "                     save_best_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSD1StKgfG2p",
        "colab_type": "text"
      },
      "source": [
        "Fitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyOcSnmJfG2p",
        "colab_type": "code",
        "outputId": "b05f87d6-6ba5-417c-e9d3-65c6a6958469",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "hist = model.fit(X_train, y_train, \n",
        "                 batch_size=256, \n",
        "                 epochs=5, \n",
        "                 verbose=1, \n",
        "                 callbacks=[es, mc], \n",
        "                 validation_data=(X_valid, y_valid))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/5\n",
            "48000/48000 [==============================] - 79s 2ms/step - loss: 0.3381 - acc: 0.8963 - val_loss: 0.0806 - val_acc: 0.9780\n",
            "Epoch 2/5\n",
            "48000/48000 [==============================] - 77s 2ms/step - loss: 0.1066 - acc: 0.9685 - val_loss: 0.0540 - val_acc: 0.9843\n",
            "Epoch 3/5\n",
            "48000/48000 [==============================] - 85s 2ms/step - loss: 0.0799 - acc: 0.9752 - val_loss: 0.0453 - val_acc: 0.9871\n",
            "Epoch 4/5\n",
            "48000/48000 [==============================] - 78s 2ms/step - loss: 0.0631 - acc: 0.9809 - val_loss: 0.0403 - val_acc: 0.9883\n",
            "Epoch 5/5\n",
            "48000/48000 [==============================] - 79s 2ms/step - loss: 0.0523 - acc: 0.9837 - val_loss: 0.0419 - val_acc: 0.9885\n",
            "CPU times: user 20min 33s, sys: 2min 26s, total: 23min\n",
            "Wall time: 6min 39s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0oq0GtvfG2s",
        "colab_type": "text"
      },
      "source": [
        "Training evolution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hx4R8vCPfG2s",
        "colab_type": "code",
        "outputId": "3f066b78-378c-490a-8bb0-ec4d18a1dae3",
        "colab": {}
      },
      "source": [
        "exp_name = \"MNIST 0-9 32Conv2D-64Conv2D-MaxPool-128-10 \"\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.suptitle(f\"{exp_name}\", fontsize=18)\n",
        "\n",
        "plt.subplot(121)\n",
        "plt.plot(hist.history[\"loss\"], label=\"Train\")\n",
        "plt.plot(hist.history[\"val_loss\"], label=\"Valid\")\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.xlabel(\"Epoch\", fontsize=14)\n",
        "plt.ylabel(\"CXE Loss\", fontsize=14)\n",
        "plt.subplot(122)\n",
        "\n",
        "plt.plot(hist.history[\"acc\"], label=\"Train\")\n",
        "plt.plot(hist.history[\"val_acc\"], label=\"Valid\")\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.xlabel(\"Epoch\", fontsize=14)\n",
        "plt.ylabel(\"Accuracy\", fontsize=14)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yhl4nLxIfG2v",
        "colab_type": "text"
      },
      "source": [
        "Load the best model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoRcTwc7fG2v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = load_model(filepath=\"chkpt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKcGhCAgfG2x",
        "colab_type": "text"
      },
      "source": [
        "Evaluate it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YC2Bkk5CfG2x",
        "colab_type": "code",
        "outputId": "bed5896f-8870-41f3-f522-220cb341d0d5",
        "colab": {}
      },
      "source": [
        "# Returns the loss value & metrics values for the model in test mode.\n",
        "# CXE and accuracy\n",
        "model.evaluate(X_test,  y_test, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 4s 438us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.03445024271312868, 0.9894]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6YSOJ9afG2z",
        "colab_type": "code",
        "outputId": "9ac19188-022b-4012-cbc0-77a0d5bd43cf",
        "colab": {}
      },
      "source": [
        "# add the result of this experiment to the log book\n",
        "expLog = pd.DataFrame(columns=[\"exp_name\",\"Train CXE Loss\", \"Train Acc\", \"Validation CXE Loss\", \"Validation  Acc\",\n",
        "                    \"Test CXE Loss\", \"Test  Accuracy\"])\n",
        "expLog.loc[len(expLog)] = [f\"{exp_name}\"] + list(np.round(np.reshape([model.evaluate(X_train, y_train, verbose=0), \n",
        "                   model.evaluate(X_valid, y_valid, verbose=0),\n",
        "                   model.evaluate(X_test,  y_test, verbose=1)], -1), 3))\n",
        "expLog"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 4s 434us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>exp_name</th>\n",
              "      <th>Train CXE Loss</th>\n",
              "      <th>Train Acc</th>\n",
              "      <th>Validation CXE Loss</th>\n",
              "      <th>Validation  Acc</th>\n",
              "      <th>Test CXE Loss</th>\n",
              "      <th>Test  Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>MNIST 0-9 32Conv2D-64Conv2D-MaxPool-128-10</td>\n",
              "      <td>0.023</td>\n",
              "      <td>0.993</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.988</td>\n",
              "      <td>0.034</td>\n",
              "      <td>0.989</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                      exp_name  Train CXE Loss  Train Acc  \\\n",
              "0  MNIST 0-9 32Conv2D-64Conv2D-MaxPool-128-10            0.023      0.993   \n",
              "\n",
              "   Validation CXE Loss  Validation  Acc  Test CXE Loss  Test  Accuracy  \n",
              "0                 0.04            0.988          0.034           0.989  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4duogMYfG21",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# If subtract pixel mean is enabled\n",
        "#if subtract_pixel_mean:\n",
        "X_train_mean = np.mean(X_train, axis=0)\n",
        "#    x_train -= x_train_mean\n",
        "#    x_test -= x_train_mean\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMcQv9APfG23",
        "colab_type": "code",
        "outputId": "53d3a96d-c794-4a85-e75f-25b8be61770c",
        "colab": {}
      },
      "source": [
        "X_train_mean.shape \n",
        "(48000, 28, 28, 1) --> (28, 28, 1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acWBL2qCfG25",
        "colab_type": "code",
        "outputId": "a3e181e1-bece-4513-a58a-72512a97e427",
        "colab": {}
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(48000, 28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zIgwjk3fG27",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}